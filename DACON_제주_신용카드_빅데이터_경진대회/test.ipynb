{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Tensorflow , keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping, Callback\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical ,Sequence, get_custom_objects\n",
    "#from swa.keras import SWA # swa optimizer - https://pypi.org/project/keras-swa/\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#etc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas : 1.0.1\n",
      "Numpy : 1.18.1\n",
      "tensorflow : 2.2.0\n",
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "print('Pandas : %s'%(pd.__version__))\n",
    "print('Numpy : %s'%(np.__version__))\n",
    "print('tensorflow : %s'%(tf.__version__))\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = pd.read_csv('data/201901-202003.csv')\n",
    "# display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = ['REG_YYMM','CARD_SIDO_NM', 'STD_CLSS_NM', 'AMT']\n",
    "# pre_data_df  = data_df[col]\n",
    "# group = pre_data_df.groupby([pre_data_df['REG_YYMM'],pre_data_df['CARD_SIDO_NM'],pre_data_df['STD_CLSS_NM']]).sum()\n",
    "# group.to_csv('data/group_myoung.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.read_csv('data/group_myoung.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REG_YYMM</th>\n",
       "      <th>CARD_SIDO_NM</th>\n",
       "      <th>STD_CLSS_NM</th>\n",
       "      <th>AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201901</td>\n",
       "      <td>강원</td>\n",
       "      <td>건강보조식품 소매업</td>\n",
       "      <td>148354746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201901</td>\n",
       "      <td>강원</td>\n",
       "      <td>골프장 운영업</td>\n",
       "      <td>1229200312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901</td>\n",
       "      <td>강원</td>\n",
       "      <td>과실 및 채소 소매업</td>\n",
       "      <td>1286979106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201901</td>\n",
       "      <td>강원</td>\n",
       "      <td>관광 민예품 및 선물용품 소매업</td>\n",
       "      <td>30656770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201901</td>\n",
       "      <td>강원</td>\n",
       "      <td>그외 기타 스포츠시설 운영업</td>\n",
       "      <td>13101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>202003</td>\n",
       "      <td>충북</td>\n",
       "      <td>피자 햄버거 샌드위치 및 유사 음식점업</td>\n",
       "      <td>1315245299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>202003</td>\n",
       "      <td>충북</td>\n",
       "      <td>한식 음식점업</td>\n",
       "      <td>16152482704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9435</th>\n",
       "      <td>202003</td>\n",
       "      <td>충북</td>\n",
       "      <td>호텔업</td>\n",
       "      <td>15248550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>202003</td>\n",
       "      <td>충북</td>\n",
       "      <td>화장품 및 방향제 소매업</td>\n",
       "      <td>428881434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>202003</td>\n",
       "      <td>충북</td>\n",
       "      <td>휴양콘도 운영업</td>\n",
       "      <td>12733490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9438 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      REG_YYMM CARD_SIDO_NM            STD_CLSS_NM          AMT\n",
       "0       201901           강원             건강보조식품 소매업    148354746\n",
       "1       201901           강원                골프장 운영업   1229200312\n",
       "2       201901           강원            과실 및 채소 소매업   1286979106\n",
       "3       201901           강원      관광 민예품 및 선물용품 소매업     30656770\n",
       "4       201901           강원        그외 기타 스포츠시설 운영업     13101500\n",
       "...        ...          ...                    ...          ...\n",
       "9433    202003           충북  피자 햄버거 샌드위치 및 유사 음식점업   1315245299\n",
       "9434    202003           충북                한식 음식점업  16152482704\n",
       "9435    202003           충북                    호텔업     15248550\n",
       "9436    202003           충북          화장품 및 방향제 소매업    428881434\n",
       "9437    202003           충북               휴양콘도 운영업     12733490\n",
       "\n",
       "[9438 rows x 4 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARD_SIDO_NM_list = list(group_df['CARD_SIDO_NM'].unique())\n",
    "STD_CLSS_NM_list =  list(group_df['STD_CLSS_NM'].unique())\n",
    "\n",
    "for i in range(len(CARD_SIDO_NM_list)):\n",
    "    tmp_city = CARD_SIDO_NM_list[i]\n",
    "    group_df['CARD_SIDO_NM'].replace(tmp_city,i,inplace=True)\n",
    "\n",
    "for i in range(len(STD_CLSS_NM_list)):\n",
    "    tmp_CLSS = STD_CLSS_NM_list[i]\n",
    "    group_df['STD_CLSS_NM'].replace(tmp_CLSS,i,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REG_YYMM</th>\n",
       "      <th>CARD_SIDO_NM</th>\n",
       "      <th>STD_CLSS_NM</th>\n",
       "      <th>AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148354746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1229200312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1286979106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30656770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>202003</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>1315245299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>202003</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>16152482704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9435</th>\n",
       "      <td>202003</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>15248550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>202003</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>428881434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>202003</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>12733490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9438 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      REG_YYMM  CARD_SIDO_NM  STD_CLSS_NM          AMT\n",
       "0       201901             0            0    148354746\n",
       "1       201901             0            1   1229200312\n",
       "2       201901             0            2   1286979106\n",
       "3       201901             0            3     30656770\n",
       "4       201901             0            4     13101500\n",
       "...        ...           ...          ...          ...\n",
       "9433    202003            16           34   1315245299\n",
       "9434    202003            16           35  16152482704\n",
       "9435    202003            16           36     15248550\n",
       "9436    202003            16           37    428881434\n",
       "9437    202003            16           38     12733490\n",
       "\n",
       "[9438 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = group_df[['REG_YYMM','CARD_SIDO_NM','STD_CLSS_NM']]\n",
    "train_Y = group_df['AMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 300)               75300     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 216,601\n",
      "Trainable params: 216,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=3))\n",
    "model.add(Dropout(0.9))\n",
    "\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.9))\n",
    "\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.9))\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.9))\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.9))\n",
    "\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.9))\n",
    "\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dropout(0.7))\n",
    "\n",
    "\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(80, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(1100, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(600, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='linear')) # OUTPUT\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rmsle(y_true, y_pred):\n",
    "       return K.sqrt(K.mean(K.square(tf.math.log1p(y_true) - tf.math.log1p(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_logarithmic_error',\n",
    "              optimizer='adam',\n",
    "              metrics=[custom_rmsle]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MLP_test'\n",
    "version = '2'\n",
    "model_path = 'data/history/'+model_name+'_'+version+'.hdf5'\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=100, \n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "modelsaver = ModelCheckpoint(\n",
    "    model_path, \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    #save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    "    #period=50\n",
    ")\n",
    "lrreducer = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=.1,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    min_lr=5e-10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('data/history/MLP_test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 231.3133 - custom_rmsle: nan\n",
      "Epoch 00001: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 231.3133 - custom_rmsle: nan - val_loss: 120.3225 - val_custom_rmsle: 10.9692 - lr: 0.0010\n",
      "Epoch 2/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 190.9790 - custom_rmsle: nan\n",
      "Epoch 00002: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 190.9790 - custom_rmsle: nan - val_loss: 103.1833 - val_custom_rmsle: 10.1579 - lr: 0.0010\n",
      "Epoch 3/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 161.1875 - custom_rmsle: nan\n",
      "Epoch 00003: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 161.1875 - custom_rmsle: nan - val_loss: 94.1386 - val_custom_rmsle: 9.7025 - lr: 0.0010\n",
      "Epoch 4/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 132.8184 - custom_rmsle: nan\n",
      "Epoch 00004: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 132.8184 - custom_rmsle: nan - val_loss: 87.7762 - val_custom_rmsle: 9.3689 - lr: 0.0010\n",
      "Epoch 5/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 110.5840 - custom_rmsle: nan\n",
      "Epoch 00005: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 110.5840 - custom_rmsle: nan - val_loss: 82.6816 - val_custom_rmsle: 9.0929 - lr: 0.0010\n",
      "Epoch 6/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 91.6462 - custom_rmsle: nan\n",
      "Epoch 00006: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 91.6462 - custom_rmsle: nan - val_loss: 78.3235 - val_custom_rmsle: 8.8501 - lr: 0.0010\n",
      "Epoch 7/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 79.9751 - custom_rmsle: nan\n",
      "Epoch 00007: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 79.9751 - custom_rmsle: nan - val_loss: 74.4722 - val_custom_rmsle: 8.6297 - lr: 0.0010\n",
      "Epoch 8/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 69.7083 - custom_rmsle: nan\n",
      "Epoch 00008: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 69.7083 - custom_rmsle: nan - val_loss: 71.0461 - val_custom_rmsle: 8.4289 - lr: 0.0010\n",
      "Epoch 9/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 59.1517 - custom_rmsle: nan\n",
      "Epoch 00009: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 59.1517 - custom_rmsle: nan - val_loss: 67.8777 - val_custom_rmsle: 8.2388 - lr: 0.0010\n",
      "Epoch 10/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 53.2100 - custom_rmsle: nan\n",
      "Epoch 00010: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 53.2100 - custom_rmsle: nan - val_loss: 64.9552 - val_custom_rmsle: 8.0595 - lr: 0.0010\n",
      "Epoch 11/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 48.3573 - custom_rmsle: nan\n",
      "Epoch 00011: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 48.3573 - custom_rmsle: nan - val_loss: 62.2146 - val_custom_rmsle: 7.8876 - lr: 0.0010\n",
      "Epoch 12/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 42.8056 - custom_rmsle: nan\n",
      "Epoch 00012: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 42.8056 - custom_rmsle: nan - val_loss: 59.6792 - val_custom_rmsle: 7.7252 - lr: 0.0010\n",
      "Epoch 13/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 39.8414 - custom_rmsle: nan\n",
      "Epoch 00013: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 39.8414 - custom_rmsle: nan - val_loss: 57.2987 - val_custom_rmsle: 7.5696 - lr: 0.0010\n",
      "Epoch 14/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 37.8325 - custom_rmsle: nan\n",
      "Epoch 00014: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 37.8325 - custom_rmsle: nan - val_loss: 55.0457 - val_custom_rmsle: 7.4193 - lr: 0.0010\n",
      "Epoch 15/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 33.8989 - custom_rmsle: nan\n",
      "Epoch 00015: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 33.8989 - custom_rmsle: nan - val_loss: 52.9264 - val_custom_rmsle: 7.2751 - lr: 0.0010\n",
      "Epoch 16/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 32.9122 - custom_rmsle: nan\n",
      "Epoch 00016: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 32.9122 - custom_rmsle: nan - val_loss: 50.9144 - val_custom_rmsle: 7.1354 - lr: 0.0010\n",
      "Epoch 17/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 31.3431 - custom_rmsle: nan\n",
      "Epoch 00017: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 31.3431 - custom_rmsle: nan - val_loss: 48.9719 - val_custom_rmsle: 6.9980 - lr: 0.0010\n",
      "Epoch 18/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 30.3968 - custom_rmsle: nan\n",
      "Epoch 00018: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 30.3968 - custom_rmsle: nan - val_loss: 47.1087 - val_custom_rmsle: 6.8636 - lr: 0.0010\n",
      "Epoch 19/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 29.0891 - custom_rmsle: nan\n",
      "Epoch 00019: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 29.0891 - custom_rmsle: nan - val_loss: 45.3262 - val_custom_rmsle: 6.7325 - lr: 0.0010\n",
      "Epoch 20/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 28.1326 - custom_rmsle: nan\n",
      "Epoch 00020: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 28.1326 - custom_rmsle: nan - val_loss: 43.6293 - val_custom_rmsle: 6.6052 - lr: 0.0010\n",
      "Epoch 21/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 26.2602 - custom_rmsle: nan\n",
      "Epoch 00021: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 26.2602 - custom_rmsle: nan - val_loss: 42.0203 - val_custom_rmsle: 6.4823 - lr: 0.0010\n",
      "Epoch 22/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 26.0708 - custom_rmsle: nan\n",
      "Epoch 00022: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 26.0708 - custom_rmsle: nan - val_loss: 40.4951 - val_custom_rmsle: 6.3636 - lr: 0.0010\n",
      "Epoch 23/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 25.3329 - custom_rmsle: nan\n",
      "Epoch 00023: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 25.3329 - custom_rmsle: nan - val_loss: 39.0539 - val_custom_rmsle: 6.2493 - lr: 0.0010\n",
      "Epoch 24/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 24.0705 - custom_rmsle: nan\n",
      "Epoch 00024: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 24.0705 - custom_rmsle: nan - val_loss: 37.6849 - val_custom_rmsle: 6.1388 - lr: 0.0010\n",
      "Epoch 25/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 24.3214 - custom_rmsle: nan\n",
      "Epoch 00025: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 24.3214 - custom_rmsle: nan - val_loss: 36.3865 - val_custom_rmsle: 6.0321 - lr: 0.0010\n",
      "Epoch 26/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 23.3630 - custom_rmsle: nan\n",
      "Epoch 00026: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 23.3630 - custom_rmsle: nan - val_loss: 35.1426 - val_custom_rmsle: 5.9281 - lr: 0.0010\n",
      "Epoch 27/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.4059 - custom_rmsle: nan\n",
      "Epoch 00027: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 22.4059 - custom_rmsle: nan - val_loss: 33.9526 - val_custom_rmsle: 5.8269 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.1126 - custom_rmsle: nan\n",
      "Epoch 00028: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 22.1126 - custom_rmsle: nan - val_loss: 32.8145 - val_custom_rmsle: 5.7284 - lr: 0.0010\n",
      "Epoch 29/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 21.5389 - custom_rmsle: nan\n",
      "Epoch 00029: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 21.5389 - custom_rmsle: nan - val_loss: 31.7255 - val_custom_rmsle: 5.6325 - lr: 0.0010\n",
      "Epoch 30/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 20.7970 - custom_rmsle: nan\n",
      "Epoch 00030: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 20.7970 - custom_rmsle: nan - val_loss: 30.6858 - val_custom_rmsle: 5.5395 - lr: 0.0010\n",
      "Epoch 31/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 21.0451 - custom_rmsle: nan\n",
      "Epoch 00031: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 21.0451 - custom_rmsle: nan - val_loss: 29.6917 - val_custom_rmsle: 5.4490 - lr: 0.0010\n",
      "Epoch 32/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 20.0969 - custom_rmsle: nan\n",
      "Epoch 00032: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 20.0969 - custom_rmsle: nan - val_loss: 28.7416 - val_custom_rmsle: 5.3611 - lr: 0.0010\n",
      "Epoch 33/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 20.4908 - custom_rmsle: nan\n",
      "Epoch 00033: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 20.4908 - custom_rmsle: nan - val_loss: 27.8250 - val_custom_rmsle: 5.2749 - lr: 0.0010\n",
      "Epoch 34/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 19.3536 - custom_rmsle: nan\n",
      "Epoch 00034: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 19.3536 - custom_rmsle: nan - val_loss: 26.9456 - val_custom_rmsle: 5.1909 - lr: 0.0010\n",
      "Epoch 35/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 19.1588 - custom_rmsle: nan\n",
      "Epoch 00035: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 19.1588 - custom_rmsle: nan - val_loss: 26.1034 - val_custom_rmsle: 5.1091 - lr: 0.0010\n",
      "Epoch 36/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 18.9032 - custom_rmsle: nan\n",
      "Epoch 00036: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 18.9032 - custom_rmsle: nan - val_loss: 25.2981 - val_custom_rmsle: 5.0297 - lr: 0.0010\n",
      "Epoch 37/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 18.1686 - custom_rmsle: nan\n",
      "Epoch 00037: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 18.1686 - custom_rmsle: nan - val_loss: 24.5266 - val_custom_rmsle: 4.9524 - lr: 0.0010\n",
      "Epoch 38/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 18.5284 - custom_rmsle: nan\n",
      "Epoch 00038: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 18.5284 - custom_rmsle: nan - val_loss: 23.7865 - val_custom_rmsle: 4.8771 - lr: 0.0010\n",
      "Epoch 39/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 17.8158 - custom_rmsle: nan\n",
      "Epoch 00039: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 17.8158 - custom_rmsle: nan - val_loss: 23.0732 - val_custom_rmsle: 4.8035 - lr: 0.0010\n",
      "Epoch 40/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 17.3869 - custom_rmsle: nan\n",
      "Epoch 00040: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 17.3869 - custom_rmsle: nan - val_loss: 22.3855 - val_custom_rmsle: 4.7313 - lr: 0.0010\n",
      "Epoch 41/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 17.2900 - custom_rmsle: nan\n",
      "Epoch 00041: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 17.2900 - custom_rmsle: nan - val_loss: 21.7277 - val_custom_rmsle: 4.6613 - lr: 0.0010\n",
      "Epoch 42/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.6964 - custom_rmsle: nan\n",
      "Epoch 00042: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 16.6964 - custom_rmsle: nan - val_loss: 21.1012 - val_custom_rmsle: 4.5936 - lr: 0.0010\n",
      "Epoch 43/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.2186 - custom_rmsle: nan\n",
      "Epoch 00043: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 16.2186 - custom_rmsle: nan - val_loss: 20.5027 - val_custom_rmsle: 4.5280 - lr: 0.0010\n",
      "Epoch 44/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.4782 - custom_rmsle: nan\n",
      "Epoch 00044: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 16.4782 - custom_rmsle: nan - val_loss: 19.9280 - val_custom_rmsle: 4.4641 - lr: 0.0010\n",
      "Epoch 45/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.4603 - custom_rmsle: nan\n",
      "Epoch 00045: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 16.4603 - custom_rmsle: nan - val_loss: 19.3809 - val_custom_rmsle: 4.4024 - lr: 0.0010\n",
      "Epoch 46/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.1157 - custom_rmsle: nan\n",
      "Epoch 00046: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 16.1157 - custom_rmsle: nan - val_loss: 18.8600 - val_custom_rmsle: 4.3428 - lr: 0.0010\n",
      "Epoch 47/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.8943 - custom_rmsle: nan\n",
      "Epoch 00047: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 15.8943 - custom_rmsle: nan - val_loss: 18.3635 - val_custom_rmsle: 4.2853 - lr: 0.0010\n",
      "Epoch 48/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.6502 - custom_rmsle: nan\n",
      "Epoch 00048: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 15.6502 - custom_rmsle: nan - val_loss: 17.8898 - val_custom_rmsle: 4.2296 - lr: 0.0010\n",
      "Epoch 49/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.5475 - custom_rmsle: nan\n",
      "Epoch 00049: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 15.5475 - custom_rmsle: nan - val_loss: 17.4381 - val_custom_rmsle: 4.1759 - lr: 0.0010\n",
      "Epoch 50/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.0436 - custom_rmsle: nan\n",
      "Epoch 00050: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 15.0436 - custom_rmsle: nan - val_loss: 17.0067 - val_custom_rmsle: 4.1239 - lr: 0.0010\n",
      "Epoch 51/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.1310 - custom_rmsle: nan   \n",
      "Epoch 00051: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 15.1310 - custom_rmsle: nan - val_loss: 16.5958 - val_custom_rmsle: 4.0738 - lr: 0.0010\n",
      "Epoch 52/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.0012 - custom_rmsle: nan\n",
      "Epoch 00052: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 15.0012 - custom_rmsle: nan - val_loss: 16.2045 - val_custom_rmsle: 4.0255 - lr: 0.0010\n",
      "Epoch 53/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.5656 - custom_rmsle: 3.8014\n",
      "Epoch 00053: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 14.5656 - custom_rmsle: 3.8014 - val_loss: 15.8333 - val_custom_rmsle: 3.9791 - lr: 0.0010\n",
      "Epoch 54/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.3845 - custom_rmsle: nan\n",
      "Epoch 00054: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 14.3845 - custom_rmsle: nan - val_loss: 15.4820 - val_custom_rmsle: 3.9347 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.4950 - custom_rmsle: nan\n",
      "Epoch 00055: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 14.4950 - custom_rmsle: nan - val_loss: 15.1474 - val_custom_rmsle: 3.8920 - lr: 0.0010\n",
      "Epoch 56/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.3461 - custom_rmsle: nan\n",
      "Epoch 00056: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 14.3461 - custom_rmsle: nan - val_loss: 14.8263 - val_custom_rmsle: 3.8505 - lr: 0.0010\n",
      "Epoch 57/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.7435 - custom_rmsle: nan\n",
      "Epoch 00057: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 13.7435 - custom_rmsle: nan - val_loss: 14.5214 - val_custom_rmsle: 3.8107 - lr: 0.0010\n",
      "Epoch 58/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.7718 - custom_rmsle: nan\n",
      "Epoch 00058: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 13.7718 - custom_rmsle: nan - val_loss: 14.2327 - val_custom_rmsle: 3.7726 - lr: 0.0010\n",
      "Epoch 59/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.6151 - custom_rmsle: 3.6877\n",
      "Epoch 00059: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 13.6151 - custom_rmsle: 3.6877 - val_loss: 13.9589 - val_custom_rmsle: 3.7362 - lr: 0.0010\n",
      "Epoch 60/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.8345 - custom_rmsle: 3.7173\n",
      "Epoch 00060: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 13.8345 - custom_rmsle: 3.7173 - val_loss: 13.6979 - val_custom_rmsle: 3.7011 - lr: 0.0010\n",
      "Epoch 61/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.4310 - custom_rmsle: nan\n",
      "Epoch 00061: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 13.4310 - custom_rmsle: nan - val_loss: 13.4493 - val_custom_rmsle: 3.6673 - lr: 0.0010\n",
      "Epoch 62/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.2302 - custom_rmsle: nan\n",
      "Epoch 00062: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 13.2302 - custom_rmsle: nan - val_loss: 13.2133 - val_custom_rmsle: 3.6350 - lr: 0.0010\n",
      "Epoch 63/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.0183 - custom_rmsle: nan\n",
      "Epoch 00063: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 13.0183 - custom_rmsle: nan - val_loss: 12.9907 - val_custom_rmsle: 3.6043 - lr: 0.0010\n",
      "Epoch 64/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.1297 - custom_rmsle: nan\n",
      "Epoch 00064: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 13.1297 - custom_rmsle: nan - val_loss: 12.7799 - val_custom_rmsle: 3.5749 - lr: 0.0010\n",
      "Epoch 65/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.8816 - custom_rmsle: 3.5815\n",
      "Epoch 00065: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 12.8816 - custom_rmsle: 3.5815 - val_loss: 12.5794 - val_custom_rmsle: 3.5467 - lr: 0.0010\n",
      "Epoch 66/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.9971 - custom_rmsle: nan\n",
      "Epoch 00066: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 12.9971 - custom_rmsle: nan - val_loss: 12.3889 - val_custom_rmsle: 3.5198 - lr: 0.0010\n",
      "Epoch 67/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.8211 - custom_rmsle: nan   \n",
      "Epoch 00067: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 12.8211 - custom_rmsle: nan - val_loss: 12.2078 - val_custom_rmsle: 3.4940 - lr: 0.0010\n",
      "Epoch 68/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.3238 - custom_rmsle: nan\n",
      "Epoch 00068: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 12.3238 - custom_rmsle: nan - val_loss: 12.0358 - val_custom_rmsle: 3.4693 - lr: 0.0010\n",
      "Epoch 69/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.2814 - custom_rmsle: 3.5055\n",
      "Epoch 00069: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 12.2814 - custom_rmsle: 3.5055 - val_loss: 11.8728 - val_custom_rmsle: 3.4457 - lr: 0.0010\n",
      "Epoch 70/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.6551 - custom_rmsle: nan\n",
      "Epoch 00070: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 12.6551 - custom_rmsle: nan - val_loss: 11.7179 - val_custom_rmsle: 3.4231 - lr: 0.0010\n",
      "Epoch 71/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.4031 - custom_rmsle: nan\n",
      "Epoch 00071: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 12.4031 - custom_rmsle: nan - val_loss: 11.5703 - val_custom_rmsle: 3.4015 - lr: 0.0010\n",
      "Epoch 72/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.3153 - custom_rmsle: 3.5072\n",
      "Epoch 00072: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 12.3153 - custom_rmsle: 3.5072 - val_loss: 11.4300 - val_custom_rmsle: 3.3808 - lr: 0.0010\n",
      "Epoch 73/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.4608 - custom_rmsle: 3.5320\n",
      "Epoch 00073: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 12.4608 - custom_rmsle: 3.5320 - val_loss: 11.2966 - val_custom_rmsle: 3.3610 - lr: 0.0010\n",
      "Epoch 74/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.2491 - custom_rmsle: 3.5067\n",
      "Epoch 00074: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 12.2491 - custom_rmsle: 3.5067 - val_loss: 11.1697 - val_custom_rmsle: 3.3421 - lr: 0.0010\n",
      "Epoch 75/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.6267 - custom_rmsle: 3.4017\n",
      "Epoch 00075: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 11.6267 - custom_rmsle: 3.4017 - val_loss: 11.0497 - val_custom_rmsle: 3.3241 - lr: 0.0010\n",
      "Epoch 76/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.3478 - custom_rmsle: nan\n",
      "Epoch 00076: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 12.3478 - custom_rmsle: nan - val_loss: 10.9362 - val_custom_rmsle: 3.3070 - lr: 0.0010\n",
      "Epoch 77/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.3083 - custom_rmsle: nan\n",
      "Epoch 00077: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 12.3083 - custom_rmsle: nan - val_loss: 10.8285 - val_custom_rmsle: 3.2907 - lr: 0.0010\n",
      "Epoch 78/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.9787 - custom_rmsle: nan\n",
      "Epoch 00078: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 11.9787 - custom_rmsle: nan - val_loss: 10.7267 - val_custom_rmsle: 3.2752 - lr: 0.0010\n",
      "Epoch 79/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.5959 - custom_rmsle: 3.4099\n",
      "Epoch 00079: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 11.5959 - custom_rmsle: 3.4099 - val_loss: 10.6300 - val_custom_rmsle: 3.2604 - lr: 0.0010\n",
      "Epoch 80/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.6319 - custom_rmsle: nan\n",
      "Epoch 00080: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 11.6319 - custom_rmsle: nan - val_loss: 10.5381 - val_custom_rmsle: 3.2462 - lr: 0.0010\n",
      "Epoch 81/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.7353 - custom_rmsle: 3.4250\n",
      "Epoch 00081: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 11.7353 - custom_rmsle: 3.4250 - val_loss: 10.4512 - val_custom_rmsle: 3.2328 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.9323 - custom_rmsle: nan\n",
      "Epoch 00082: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 11.9323 - custom_rmsle: nan - val_loss: 10.3687 - val_custom_rmsle: 3.2201 - lr: 0.0010\n",
      "Epoch 83/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.7839 - custom_rmsle: nan\n",
      "Epoch 00083: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 11.7839 - custom_rmsle: nan - val_loss: 10.2912 - val_custom_rmsle: 3.2080 - lr: 0.0010\n",
      "Epoch 84/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.8713 - custom_rmsle: nan\n",
      "Epoch 00084: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 11.8713 - custom_rmsle: nan - val_loss: 10.2180 - val_custom_rmsle: 3.1966 - lr: 0.0010\n",
      "Epoch 85/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.6067 - custom_rmsle: 3.3900\n",
      "Epoch 00085: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 11.6067 - custom_rmsle: 3.3900 - val_loss: 10.1487 - val_custom_rmsle: 3.1857 - lr: 0.0010\n",
      "Epoch 86/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.3294 - custom_rmsle: 3.3691\n",
      "Epoch 00086: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 11.3294 - custom_rmsle: 3.3691 - val_loss: 10.0834 - val_custom_rmsle: 3.1754 - lr: 0.0010\n",
      "Epoch 87/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.4231 - custom_rmsle: nan   \n",
      "Epoch 00087: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 11.4231 - custom_rmsle: nan - val_loss: 10.0216 - val_custom_rmsle: 3.1657 - lr: 0.0010\n",
      "Epoch 88/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.5420 - custom_rmsle: nan\n",
      "Epoch 00088: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 11.5420 - custom_rmsle: nan - val_loss: 9.9634 - val_custom_rmsle: 3.1565 - lr: 0.0010\n",
      "Epoch 89/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9540 - custom_rmsle: nan   \n",
      "Epoch 00089: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.9540 - custom_rmsle: nan - val_loss: 9.9085 - val_custom_rmsle: 3.1478 - lr: 0.0010\n",
      "Epoch 90/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9717 - custom_rmsle: nan\n",
      "Epoch 00090: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 10.9717 - custom_rmsle: nan - val_loss: 9.8569 - val_custom_rmsle: 3.1396 - lr: 0.0010\n",
      "Epoch 91/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.0895 - custom_rmsle: nan\n",
      "Epoch 00091: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 11.0895 - custom_rmsle: nan - val_loss: 9.8082 - val_custom_rmsle: 3.1318 - lr: 0.0010\n",
      "Epoch 92/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9698 - custom_rmsle: 3.3099\n",
      "Epoch 00092: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.9698 - custom_rmsle: 3.3099 - val_loss: 9.7622 - val_custom_rmsle: 3.1245 - lr: 0.0010\n",
      "Epoch 93/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.2338 - custom_rmsle: nan\n",
      "Epoch 00093: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 11.2338 - custom_rmsle: nan - val_loss: 9.7188 - val_custom_rmsle: 3.1175 - lr: 0.0010\n",
      "Epoch 94/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.0475 - custom_rmsle: 3.3158\n",
      "Epoch 00094: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 11.0475 - custom_rmsle: 3.3158 - val_loss: 9.6781 - val_custom_rmsle: 3.1110 - lr: 0.0010\n",
      "Epoch 95/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.1471 - custom_rmsle: nan\n",
      "Epoch 00095: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 11.1471 - custom_rmsle: nan - val_loss: 9.6401 - val_custom_rmsle: 3.1048 - lr: 0.0010\n",
      "Epoch 96/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.1379 - custom_rmsle: 3.3340\n",
      "Epoch 00096: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 11.1379 - custom_rmsle: 3.3340 - val_loss: 9.6041 - val_custom_rmsle: 3.0991 - lr: 0.0010\n",
      "Epoch 97/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.0565 - custom_rmsle: 3.3320\n",
      "Epoch 00097: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 11.0565 - custom_rmsle: 3.3320 - val_loss: 9.5700 - val_custom_rmsle: 3.0935 - lr: 0.0010\n",
      "Epoch 98/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9924 - custom_rmsle: 3.3041\n",
      "Epoch 00098: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 10.9924 - custom_rmsle: 3.3041 - val_loss: 9.5381 - val_custom_rmsle: 3.0884 - lr: 0.0010\n",
      "Epoch 99/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.2227 - custom_rmsle: nan\n",
      "Epoch 00099: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 11.2227 - custom_rmsle: nan - val_loss: 9.5078 - val_custom_rmsle: 3.0835 - lr: 0.0010\n",
      "Epoch 100/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9672 - custom_rmsle: nan   \n",
      "Epoch 00100: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 10.9672 - custom_rmsle: nan - val_loss: 9.4794 - val_custom_rmsle: 3.0789 - lr: 0.0010\n",
      "Epoch 101/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7962 - custom_rmsle: 3.2649\n",
      "Epoch 00101: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 10.7962 - custom_rmsle: 3.2649 - val_loss: 9.4525 - val_custom_rmsle: 3.0745 - lr: 0.0010\n",
      "Epoch 102/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.8525 - custom_rmsle: nan   \n",
      "Epoch 00102: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 10.8525 - custom_rmsle: nan - val_loss: 9.4272 - val_custom_rmsle: 3.0704 - lr: 0.0010\n",
      "Epoch 103/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7958 - custom_rmsle: nan\n",
      "Epoch 00103: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 10.7958 - custom_rmsle: nan - val_loss: 9.4035 - val_custom_rmsle: 3.0665 - lr: 0.0010\n",
      "Epoch 104/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7428 - custom_rmsle: nan   \n",
      "Epoch 00104: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 10.7428 - custom_rmsle: nan - val_loss: 9.3814 - val_custom_rmsle: 3.0629 - lr: 0.0010\n",
      "Epoch 105/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.8050 - custom_rmsle: 3.3064\n",
      "Epoch 00105: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 10.8050 - custom_rmsle: 3.3064 - val_loss: 9.3608 - val_custom_rmsle: 3.0595 - lr: 0.0010\n",
      "Epoch 106/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7333 - custom_rmsle: 3.2918\n",
      "Epoch 00106: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 10.7333 - custom_rmsle: 3.2918 - val_loss: 9.3415 - val_custom_rmsle: 3.0564 - lr: 0.0010\n",
      "Epoch 107/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7417 - custom_rmsle: nan\n",
      "Epoch 00107: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 10.7417 - custom_rmsle: nan - val_loss: 9.3234 - val_custom_rmsle: 3.0534 - lr: 0.0010\n",
      "Epoch 108/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5180 - custom_rmsle: 3.2179\n",
      "Epoch 00108: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 10.5180 - custom_rmsle: 3.2179 - val_loss: 9.3066 - val_custom_rmsle: 3.0507 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6470 - custom_rmsle: nan\n",
      "Epoch 00109: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 10.6470 - custom_rmsle: nan - val_loss: 9.2911 - val_custom_rmsle: 3.0481 - lr: 0.0010\n",
      "Epoch 110/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9584 - custom_rmsle: 3.3072\n",
      "Epoch 00110: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.9584 - custom_rmsle: 3.3072 - val_loss: 9.2767 - val_custom_rmsle: 3.0458 - lr: 0.0010\n",
      "Epoch 111/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7338 - custom_rmsle: nan\n",
      "Epoch 00111: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 10.7338 - custom_rmsle: nan - val_loss: 9.2632 - val_custom_rmsle: 3.0435 - lr: 0.0010\n",
      "Epoch 112/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6208 - custom_rmsle: 3.2697\n",
      "Epoch 00112: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 10.6208 - custom_rmsle: 3.2697 - val_loss: 9.2506 - val_custom_rmsle: 3.0415 - lr: 0.0010\n",
      "Epoch 113/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9948 - custom_rmsle: nan\n",
      "Epoch 00113: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 10.9948 - custom_rmsle: nan - val_loss: 9.2388 - val_custom_rmsle: 3.0395 - lr: 0.0010\n",
      "Epoch 114/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6407 - custom_rmsle: 3.2780\n",
      "Epoch 00114: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 10.6407 - custom_rmsle: 3.2780 - val_loss: 9.2278 - val_custom_rmsle: 3.0377 - lr: 0.0010\n",
      "Epoch 115/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7979 - custom_rmsle: 3.2928\n",
      "Epoch 00115: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 10.7979 - custom_rmsle: 3.2928 - val_loss: 9.2176 - val_custom_rmsle: 3.0361 - lr: 0.0010\n",
      "Epoch 116/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.0442 - custom_rmsle: nan\n",
      "Epoch 00116: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 11.0442 - custom_rmsle: nan - val_loss: 9.2081 - val_custom_rmsle: 3.0345 - lr: 0.0010\n",
      "Epoch 117/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7103 - custom_rmsle: 3.2912\n",
      "Epoch 00117: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.7103 - custom_rmsle: 3.2912 - val_loss: 9.1994 - val_custom_rmsle: 3.0331 - lr: 0.0010\n",
      "Epoch 118/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2840 - custom_rmsle: 3.2195\n",
      "Epoch 00118: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.2840 - custom_rmsle: 3.2195 - val_loss: 9.1914 - val_custom_rmsle: 3.0317 - lr: 0.0010\n",
      "Epoch 119/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6143 - custom_rmsle: 3.2738\n",
      "Epoch 00119: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 10.6143 - custom_rmsle: 3.2738 - val_loss: 9.1840 - val_custom_rmsle: 3.0305 - lr: 0.0010\n",
      "Epoch 120/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7604 - custom_rmsle: nan\n",
      "Epoch 00120: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 10.7604 - custom_rmsle: nan - val_loss: 9.1771 - val_custom_rmsle: 3.0294 - lr: 0.0010\n",
      "Epoch 121/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5105 - custom_rmsle: nan\n",
      "Epoch 00121: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 10.5105 - custom_rmsle: nan - val_loss: 9.1708 - val_custom_rmsle: 3.0283 - lr: 0.0010\n",
      "Epoch 122/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6080 - custom_rmsle: nan\n",
      "Epoch 00122: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.6080 - custom_rmsle: nan - val_loss: 9.1649 - val_custom_rmsle: 3.0274 - lr: 0.0010\n",
      "Epoch 123/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5654 - custom_rmsle: 3.2720\n",
      "Epoch 00123: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 10.5654 - custom_rmsle: 3.2720 - val_loss: 9.1596 - val_custom_rmsle: 3.0265 - lr: 0.0010\n",
      "Epoch 124/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2375 - custom_rmsle: 3.1797\n",
      "Epoch 00124: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 10.2375 - custom_rmsle: 3.1797 - val_loss: 9.1547 - val_custom_rmsle: 3.0257 - lr: 0.0010\n",
      "Epoch 125/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5732 - custom_rmsle: 3.2508\n",
      "Epoch 00125: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 10.5732 - custom_rmsle: 3.2508 - val_loss: 9.1502 - val_custom_rmsle: 3.0249 - lr: 0.0010\n",
      "Epoch 126/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9647 - custom_rmsle: 3.3032\n",
      "Epoch 00126: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 10.9647 - custom_rmsle: 3.3032 - val_loss: 9.1461 - val_custom_rmsle: 3.0243 - lr: 0.0010\n",
      "Epoch 127/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3831 - custom_rmsle: 3.2219\n",
      "Epoch 00127: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 10.3831 - custom_rmsle: 3.2219 - val_loss: 9.1423 - val_custom_rmsle: 3.0236 - lr: 0.0010\n",
      "Epoch 128/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5154 - custom_rmsle: nan\n",
      "Epoch 00128: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 10.5154 - custom_rmsle: nan - val_loss: 9.1389 - val_custom_rmsle: 3.0231 - lr: 0.0010\n",
      "Epoch 129/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5508 - custom_rmsle: nan\n",
      "Epoch 00129: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 10.5508 - custom_rmsle: nan - val_loss: 9.1359 - val_custom_rmsle: 3.0226 - lr: 0.0010\n",
      "Epoch 130/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5058 - custom_rmsle: nan\n",
      "Epoch 00130: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 10.5058 - custom_rmsle: nan - val_loss: 9.1332 - val_custom_rmsle: 3.0221 - lr: 0.0010\n",
      "Epoch 131/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6690 - custom_rmsle: nan\n",
      "Epoch 00131: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 10.6690 - custom_rmsle: nan - val_loss: 9.1308 - val_custom_rmsle: 3.0217 - lr: 0.0010\n",
      "Epoch 132/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4043 - custom_rmsle: 3.2444\n",
      "Epoch 00132: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 10.4043 - custom_rmsle: 3.2444 - val_loss: 9.1286 - val_custom_rmsle: 3.0214 - lr: 0.0010\n",
      "Epoch 133/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6922 - custom_rmsle: nan\n",
      "Epoch 00133: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 10.6922 - custom_rmsle: nan - val_loss: 9.1267 - val_custom_rmsle: 3.0210 - lr: 0.0010\n",
      "Epoch 134/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3402 - custom_rmsle: 3.1984\n",
      "Epoch 00134: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 10.3402 - custom_rmsle: 3.1984 - val_loss: 9.1251 - val_custom_rmsle: 3.0208 - lr: 0.0010\n",
      "Epoch 135/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7490 - custom_rmsle: nan\n",
      "Epoch 00135: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.7490 - custom_rmsle: nan - val_loss: 9.1236 - val_custom_rmsle: 3.0205 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7273 - custom_rmsle: nan\n",
      "Epoch 00136: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.7273 - custom_rmsle: nan - val_loss: 9.1224 - val_custom_rmsle: 3.0203 - lr: 0.0010\n",
      "Epoch 137/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6896 - custom_rmsle: nan\n",
      "Epoch 00137: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.6896 - custom_rmsle: nan - val_loss: 9.1213 - val_custom_rmsle: 3.0201 - lr: 0.0010\n",
      "Epoch 138/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4107 - custom_rmsle: 3.2211\n",
      "Epoch 00138: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 10.4107 - custom_rmsle: 3.2211 - val_loss: 9.1203 - val_custom_rmsle: 3.0200 - lr: 0.0010\n",
      "Epoch 139/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2107 - custom_rmsle: 3.1800\n",
      "Epoch 00139: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 10.2107 - custom_rmsle: 3.1800 - val_loss: 9.1195 - val_custom_rmsle: 3.0199 - lr: 0.0010\n",
      "Epoch 140/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6315 - custom_rmsle: 3.2429\n",
      "Epoch 00140: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 10.6315 - custom_rmsle: 3.2429 - val_loss: 9.1189 - val_custom_rmsle: 3.0198 - lr: 0.0010\n",
      "Epoch 141/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6657 - custom_rmsle: 3.2530\n",
      "Epoch 00141: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.6657 - custom_rmsle: 3.2530 - val_loss: 9.1184 - val_custom_rmsle: 3.0197 - lr: 0.0010\n",
      "Epoch 142/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7064 - custom_rmsle: nan   \n",
      "Epoch 00142: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.7064 - custom_rmsle: nan - val_loss: 9.1180 - val_custom_rmsle: 3.0196 - lr: 0.0010\n",
      "Epoch 143/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5994 - custom_rmsle: nan   \n",
      "Epoch 00143: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 10.5994 - custom_rmsle: nan - val_loss: 9.1177 - val_custom_rmsle: 3.0196 - lr: 0.0010\n",
      "Epoch 144/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2828 - custom_rmsle: 3.1929\n",
      "Epoch 00144: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 10.2828 - custom_rmsle: 3.1929 - val_loss: 9.1176 - val_custom_rmsle: 3.0195 - lr: 0.0010\n",
      "Epoch 145/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3961 - custom_rmsle: nan   \n",
      "Epoch 00145: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.3961 - custom_rmsle: nan - val_loss: 9.1175 - val_custom_rmsle: 3.0195 - lr: 0.0010\n",
      "Epoch 146/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3467 - custom_rmsle: 3.2093\n",
      "Epoch 00146: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 10.3467 - custom_rmsle: 3.2093 - val_loss: 9.1175 - val_custom_rmsle: 3.0195 - lr: 0.0010\n",
      "Epoch 147/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3720 - custom_rmsle: 3.2023\n",
      "Epoch 00147: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 10.3720 - custom_rmsle: 3.2023 - val_loss: 9.1176 - val_custom_rmsle: 3.0195 - lr: 0.0010\n",
      "Epoch 148/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4062 - custom_rmsle: 3.2307\n",
      "Epoch 00148: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 10.4062 - custom_rmsle: 3.2307 - val_loss: 9.1177 - val_custom_rmsle: 3.0196 - lr: 0.0010\n",
      "Epoch 149/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4359 - custom_rmsle: 3.2345\n",
      "Epoch 00149: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 10.4359 - custom_rmsle: 3.2345 - val_loss: 9.1179 - val_custom_rmsle: 3.0196 - lr: 0.0010\n",
      "Epoch 150/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.1568 - custom_rmsle: nan\n",
      "Epoch 00150: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 10.1568 - custom_rmsle: nan - val_loss: 9.1181 - val_custom_rmsle: 3.0196 - lr: 0.0010\n",
      "Epoch 151/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5974 - custom_rmsle: 3.2560\n",
      "Epoch 00151: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 10.5974 - custom_rmsle: 3.2560 - val_loss: 9.1184 - val_custom_rmsle: 3.0197 - lr: 0.0010\n",
      "Epoch 152/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7909 - custom_rmsle: 3.2885\n",
      "Epoch 00152: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 10.7909 - custom_rmsle: 3.2885 - val_loss: 9.1187 - val_custom_rmsle: 3.0197 - lr: 0.0010\n",
      "Epoch 153/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4950 - custom_rmsle: nan   \n",
      "Epoch 00153: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 10.4950 - custom_rmsle: nan - val_loss: 9.1190 - val_custom_rmsle: 3.0198 - lr: 0.0010\n",
      "Epoch 154/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3685 - custom_rmsle: nan\n",
      "Epoch 00154: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 10.3685 - custom_rmsle: nan - val_loss: 9.1194 - val_custom_rmsle: 3.0198 - lr: 0.0010\n",
      "Epoch 155/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.8945 - custom_rmsle: 3.2906\n",
      "Epoch 00155: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.8945 - custom_rmsle: 3.2906 - val_loss: 9.1198 - val_custom_rmsle: 3.0199 - lr: 0.0010\n",
      "Epoch 156/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3806 - custom_rmsle: 3.2215\n",
      "Epoch 00156: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 10.3806 - custom_rmsle: 3.2215 - val_loss: 9.1202 - val_custom_rmsle: 3.0200 - lr: 0.0010\n",
      "Epoch 157/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.0533 - custom_rmsle: 3.3409\n",
      "Epoch 00157: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 11.0533 - custom_rmsle: 3.3409 - val_loss: 9.1207 - val_custom_rmsle: 3.0201 - lr: 0.0010\n",
      "Epoch 158/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5978 - custom_rmsle: 3.2464\n",
      "Epoch 00158: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 10.5978 - custom_rmsle: 3.2464 - val_loss: 9.1213 - val_custom_rmsle: 3.0201 - lr: 0.0010\n",
      "Epoch 159/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4723 - custom_rmsle: nan\n",
      "Epoch 00159: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 10.4723 - custom_rmsle: nan - val_loss: 9.1218 - val_custom_rmsle: 3.0202 - lr: 0.0010\n",
      "Epoch 160/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4029 - custom_rmsle: 3.2251\n",
      "Epoch 00160: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.4029 - custom_rmsle: 3.2251 - val_loss: 9.1223 - val_custom_rmsle: 3.0203 - lr: 0.0010\n",
      "Epoch 161/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3418 - custom_rmsle: 3.1876\n",
      "Epoch 00161: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 10.3418 - custom_rmsle: 3.1876 - val_loss: 9.1228 - val_custom_rmsle: 3.0204 - lr: 0.0010\n",
      "Epoch 162/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4040 - custom_rmsle: nan\n",
      "Epoch 00162: saving model to data/history/MLP_test_2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 149ms/step - loss: 10.4040 - custom_rmsle: nan - val_loss: 9.1233 - val_custom_rmsle: 3.0205 - lr: 0.0010\n",
      "Epoch 163/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3013 - custom_rmsle: nan\n",
      "Epoch 00163: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 10.3013 - custom_rmsle: nan - val_loss: 9.1238 - val_custom_rmsle: 3.0206 - lr: 0.0010\n",
      "Epoch 164/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4974 - custom_rmsle: 3.2461\n",
      "Epoch 00164: saving model to data/history/MLP_test_2.hdf5\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 10.4974 - custom_rmsle: 3.2461 - val_loss: 9.1243 - val_custom_rmsle: 3.0207 - lr: 0.0010\n",
      "Epoch 165/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3317 - custom_rmsle: 3.2235\n",
      "Epoch 00165: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 10.3317 - custom_rmsle: 3.2235 - val_loss: 9.1244 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 166/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3768 - custom_rmsle: 3.2100\n",
      "Epoch 00166: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 10.3768 - custom_rmsle: 3.2100 - val_loss: 9.1244 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 167/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7263 - custom_rmsle: 3.2683\n",
      "Epoch 00167: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 10.7263 - custom_rmsle: 3.2683 - val_loss: 9.1245 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 168/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3618 - custom_rmsle: 3.2186\n",
      "Epoch 00168: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 10.3618 - custom_rmsle: 3.2186 - val_loss: 9.1245 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 169/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5058 - custom_rmsle: 3.2496\n",
      "Epoch 00169: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 10.5058 - custom_rmsle: 3.2496 - val_loss: 9.1246 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 170/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5676 - custom_rmsle: 3.2454\n",
      "Epoch 00170: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.5676 - custom_rmsle: 3.2454 - val_loss: 9.1246 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 171/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7522 - custom_rmsle: nan\n",
      "Epoch 00171: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 10.7522 - custom_rmsle: nan - val_loss: 9.1247 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 172/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4195 - custom_rmsle: 3.2357\n",
      "Epoch 00172: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 10.4195 - custom_rmsle: 3.2357 - val_loss: 9.1247 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 173/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3202 - custom_rmsle: 3.1984\n",
      "Epoch 00173: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 10.3202 - custom_rmsle: 3.1984 - val_loss: 9.1248 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 174/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5929 - custom_rmsle: 3.2476\n",
      "Epoch 00174: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.5929 - custom_rmsle: 3.2476 - val_loss: 9.1248 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 175/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2597 - custom_rmsle: 3.1933\n",
      "Epoch 00175: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 10.2597 - custom_rmsle: 3.1933 - val_loss: 9.1248 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 176/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6306 - custom_rmsle: nan\n",
      "Epoch 00176: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 10.6306 - custom_rmsle: nan - val_loss: 9.1249 - val_custom_rmsle: 3.0207 - lr: 1.0000e-04\n",
      "Epoch 177/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3881 - custom_rmsle: 3.2234\n",
      "Epoch 00177: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.3881 - custom_rmsle: 3.2234 - val_loss: 9.1249 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 178/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7175 - custom_rmsle: nan\n",
      "Epoch 00178: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 10.7175 - custom_rmsle: nan - val_loss: 9.1250 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 179/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2822 - custom_rmsle: 3.2019\n",
      "Epoch 00179: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.2822 - custom_rmsle: 3.2019 - val_loss: 9.1250 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 180/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3481 - custom_rmsle: nan   \n",
      "Epoch 00180: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 10.3481 - custom_rmsle: nan - val_loss: 9.1251 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 181/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5700 - custom_rmsle: 3.2522\n",
      "Epoch 00181: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.5700 - custom_rmsle: 3.2522 - val_loss: 9.1251 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 182/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2750 - custom_rmsle: nan\n",
      "Epoch 00182: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 10.2750 - custom_rmsle: nan - val_loss: 9.1251 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 183/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4733 - custom_rmsle: 3.2255\n",
      "Epoch 00183: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 10.4733 - custom_rmsle: 3.2255 - val_loss: 9.1252 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 184/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2115 - custom_rmsle: 3.1854\n",
      "Epoch 00184: saving model to data/history/MLP_test_2.hdf5\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 10.2115 - custom_rmsle: 3.1854 - val_loss: 9.1252 - val_custom_rmsle: 3.0208 - lr: 1.0000e-04\n",
      "Epoch 185/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4704 - custom_rmsle: nan\n",
      "Epoch 00185: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.4704 - custom_rmsle: nan - val_loss: 9.1252 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 186/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3131 - custom_rmsle: 3.2067\n",
      "Epoch 00186: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 10.3131 - custom_rmsle: 3.2067 - val_loss: 9.1252 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 187/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3367 - custom_rmsle: 3.2303\n",
      "Epoch 00187: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 10.3367 - custom_rmsle: 3.2303 - val_loss: 9.1252 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 188/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 10.1098 - custom_rmsle: 3.1696\n",
      "Epoch 00188: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 10.1098 - custom_rmsle: 3.1696 - val_loss: 9.1252 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 189/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5026 - custom_rmsle: 3.2375\n",
      "Epoch 00189: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 10.5026 - custom_rmsle: 3.2375 - val_loss: 9.1252 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 190/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6585 - custom_rmsle: 3.2642\n",
      "Epoch 00190: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.6585 - custom_rmsle: 3.2642 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 191/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5399 - custom_rmsle: nan\n",
      "Epoch 00191: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 10.5399 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 192/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4875 - custom_rmsle: 3.2262\n",
      "Epoch 00192: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.4875 - custom_rmsle: 3.2262 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 193/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3823 - custom_rmsle: nan\n",
      "Epoch 00193: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 10.3823 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 194/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5597 - custom_rmsle: 3.2537\n",
      "Epoch 00194: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.5597 - custom_rmsle: 3.2537 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 195/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4705 - custom_rmsle: nan\n",
      "Epoch 00195: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 10.4705 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 196/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5550 - custom_rmsle: 3.2389\n",
      "Epoch 00196: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.5550 - custom_rmsle: 3.2389 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 197/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4322 - custom_rmsle: 3.2313\n",
      "Epoch 00197: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 10.4322 - custom_rmsle: 3.2313 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 198/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3751 - custom_rmsle: 3.2352\n",
      "Epoch 00198: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 10.3751 - custom_rmsle: 3.2352 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 199/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7158 - custom_rmsle: nan\n",
      "Epoch 00199: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.7158 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 200/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3589 - custom_rmsle: 3.2175\n",
      "Epoch 00200: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 10.3589 - custom_rmsle: 3.2175 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 201/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6951 - custom_rmsle: 3.2705\n",
      "Epoch 00201: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.6951 - custom_rmsle: 3.2705 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 202/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6875 - custom_rmsle: nan\n",
      "Epoch 00202: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.6875 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 203/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7806 - custom_rmsle: nan\n",
      "Epoch 00203: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 10.7806 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 204/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3863 - custom_rmsle: nan\n",
      "Epoch 00204: saving model to data/history/MLP_test_2.hdf5\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 10.3863 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-05\n",
      "Epoch 205/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4376 - custom_rmsle: nan\n",
      "Epoch 00205: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 10.4376 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 206/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3413 - custom_rmsle: nan\n",
      "Epoch 00206: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 10.3413 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 207/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6027 - custom_rmsle: 3.2512\n",
      "Epoch 00207: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.6027 - custom_rmsle: 3.2512 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 208/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.0804 - custom_rmsle: 3.1719\n",
      "Epoch 00208: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 10.0804 - custom_rmsle: 3.1719 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 209/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3531 - custom_rmsle: nan\n",
      "Epoch 00209: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 10.3531 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 210/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5230 - custom_rmsle: 3.2380\n",
      "Epoch 00210: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.5230 - custom_rmsle: 3.2380 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 211/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3888 - custom_rmsle: 3.2239\n",
      "Epoch 00211: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 10.3888 - custom_rmsle: 3.2239 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 212/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4919 - custom_rmsle: 3.2521\n",
      "Epoch 00212: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.4919 - custom_rmsle: 3.2521 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 213/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5702 - custom_rmsle: 3.2411\n",
      "Epoch 00213: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 10.5702 - custom_rmsle: 3.2411 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4456 - custom_rmsle: nan   \n",
      "Epoch 00214: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 10.4456 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 215/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3209 - custom_rmsle: 3.2292\n",
      "Epoch 00215: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 10.3209 - custom_rmsle: 3.2292 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 216/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3413 - custom_rmsle: nan\n",
      "Epoch 00216: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 10.3413 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 217/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7898 - custom_rmsle: nan\n",
      "Epoch 00217: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 10.7898 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 218/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5279 - custom_rmsle: 3.2635\n",
      "Epoch 00218: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 10.5279 - custom_rmsle: 3.2635 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 219/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.1700 - custom_rmsle: nan\n",
      "Epoch 00219: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 10.1700 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 220/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4858 - custom_rmsle: nan\n",
      "Epoch 00220: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 10.4858 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 221/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.0442 - custom_rmsle: 3.1816\n",
      "Epoch 00221: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 10.0442 - custom_rmsle: 3.1816 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 222/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5552 - custom_rmsle: nan\n",
      "Epoch 00222: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.5552 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 223/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.8702 - custom_rmsle: nan\n",
      "Epoch 00223: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 10.8702 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 224/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3203 - custom_rmsle: 3.2173\n",
      "Epoch 00224: saving model to data/history/MLP_test_2.hdf5\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 10.3203 - custom_rmsle: 3.2173 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-06\n",
      "Epoch 225/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4523 - custom_rmsle: 3.2124\n",
      "Epoch 00225: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 10.4523 - custom_rmsle: 3.2124 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 226/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4357 - custom_rmsle: nan\n",
      "Epoch 00226: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.4357 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 227/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4023 - custom_rmsle: 3.2266\n",
      "Epoch 00227: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 10.4023 - custom_rmsle: 3.2266 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 228/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3238 - custom_rmsle: nan\n",
      "Epoch 00228: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.3238 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 229/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5853 - custom_rmsle: 3.2403\n",
      "Epoch 00229: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 10.5853 - custom_rmsle: 3.2403 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 230/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4481 - custom_rmsle: nan\n",
      "Epoch 00230: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 10.4481 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 231/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.1839 - custom_rmsle: nan   \n",
      "Epoch 00231: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 10.1839 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 232/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7361 - custom_rmsle: nan\n",
      "Epoch 00232: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 10.7361 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 233/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4824 - custom_rmsle: 3.2404\n",
      "Epoch 00233: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.4824 - custom_rmsle: 3.2404 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 234/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4468 - custom_rmsle: 3.2165\n",
      "Epoch 00234: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 10.4468 - custom_rmsle: 3.2165 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 235/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2822 - custom_rmsle: 3.1922\n",
      "Epoch 00235: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 10.2822 - custom_rmsle: 3.1922 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 236/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4059 - custom_rmsle: 3.2277\n",
      "Epoch 00236: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 10.4059 - custom_rmsle: 3.2277 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 237/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5519 - custom_rmsle: nan   \n",
      "Epoch 00237: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 10.5519 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 238/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2291 - custom_rmsle: 3.1689\n",
      "Epoch 00238: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 10.2291 - custom_rmsle: 3.1689 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 239/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5371 - custom_rmsle: nan\n",
      "Epoch 00239: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 10.5371 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6013 - custom_rmsle: 3.2536\n",
      "Epoch 00240: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 10.6013 - custom_rmsle: 3.2536 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 241/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5824 - custom_rmsle: nan\n",
      "Epoch 00241: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 10.5824 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 242/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5265 - custom_rmsle: 3.2484\n",
      "Epoch 00242: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 10.5265 - custom_rmsle: 3.2484 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 243/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7094 - custom_rmsle: nan\n",
      "Epoch 00243: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 10.7094 - custom_rmsle: nan - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 244/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2545 - custom_rmsle: 3.2016\n",
      "Epoch 00244: saving model to data/history/MLP_test_2.hdf5\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 10.2545 - custom_rmsle: 3.2016 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-07\n",
      "Epoch 245/50000\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.8958 - custom_rmsle: 3.2780\n",
      "Epoch 00245: saving model to data/history/MLP_test_2.hdf5\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 10.8958 - custom_rmsle: 3.2780 - val_loss: 9.1253 - val_custom_rmsle: 3.0208 - lr: 1.0000e-08\n",
      "Epoch 00245: early stopping\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 50000\n",
    "batch_size_num = 6000\n",
    "validation_split_nm =  0.05\n",
    "hist = model.fit(train_X, \n",
    "                 train_Y, \n",
    "                 epochs=epoch_num, \n",
    "                 batch_size=batch_size_num, \n",
    "                 validation_split=validation_split_nm, \n",
    "                 callbacks=[earlystopper,modelsaver,lrreducer]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_file = 'data/history/history_{}.txt'.format(str(version))\n",
    "dict_to_save = {}\n",
    "for k, v in hist.history.items():\n",
    "    dict_to_save.update({k: [np.format_float_positional(x) for x in hist.history[k]]})\n",
    "with open(history_file, 'w') as file:\n",
    "    json.dump(dict_to_save, file)\n",
    "ep_max = epoch_num\n",
    "plt.plot(hist.history['loss'][:ep_max], label='loss')\n",
    "plt.plot(hist.history['val_loss'][:ep_max], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(hist.history['custom_rmsle'][:ep_max], label='custom_rmsle')\n",
    "plt.plot(hist.history['val_custom_rmsle'][:ep_max], label='val_custom_rmsle')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUBMISSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sub = sub_df.copy()\n",
    "#sub_CARD_SIDO_NM_list = list(tmp_sub['CARD_SIDO_NM'].unique())\n",
    "#sub_STD_CLSS_NM_list =  list(tmp_sub['STD_CLSS_NM'].unique())\n",
    "\n",
    "for i in range(len(CARD_SIDO_NM_list)):\n",
    "    tmp_city = CARD_SIDO_NM_list[i]\n",
    "    tmp_sub['CARD_SIDO_NM'].replace(tmp_city,i,inplace=True)\n",
    "\n",
    "for i in range(len(STD_CLSS_NM_list)):\n",
    "    tmp_CLSS = STD_CLSS_NM_list[i]\n",
    "    tmp_sub['STD_CLSS_NM'].replace(tmp_CLSS,i,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>REG_YYMM</th>\n",
       "      <th>CARD_SIDO_NM</th>\n",
       "      <th>STD_CLSS_NM</th>\n",
       "      <th>AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>202004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>202004</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>202004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>202004</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>1389</td>\n",
       "      <td>202007</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1390</td>\n",
       "      <td>202007</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1391</td>\n",
       "      <td>202007</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>1392</td>\n",
       "      <td>202007</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1393</td>\n",
       "      <td>202007</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1394 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  REG_YYMM  CARD_SIDO_NM  STD_CLSS_NM  AMT\n",
       "0        0    202004             0            0    0\n",
       "1        1    202004             0            1    0\n",
       "2        2    202004             0            2    0\n",
       "3        3    202004             0            3    0\n",
       "4        4    202004             0           39    0\n",
       "...    ...       ...           ...          ...  ...\n",
       "1389  1389    202007            16           34    0\n",
       "1390  1390    202007            16           35    0\n",
       "1391  1391    202007            16           36    0\n",
       "1392  1392    202007            16           37    0\n",
       "1393  1393    202007            16           38    0\n",
       "\n",
       "[1394 rows x 5 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = tmp_sub[['REG_YYMM','CARD_SIDO_NM','STD_CLSS_NM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.506284e+08]\n",
      "[4.5062893e+08]\n",
      "[4.5062957e+08]\n",
      "[4.5063008e+08]\n",
      "[4.5065e+08]\n",
      "[4.506306e+08]\n",
      "[4.5063117e+08]\n",
      "[4.5063178e+08]\n",
      "[4.5063226e+08]\n",
      "[4.5063283e+08]\n",
      "[4.5063344e+08]\n",
      "[4.5063395e+08]\n",
      "[4.506345e+08]\n",
      "[4.5063504e+08]\n",
      "[4.5063565e+08]\n",
      "[4.5063616e+08]\n",
      "[4.5063667e+08]\n",
      "[4.506373e+08]\n",
      "[4.5063782e+08]\n",
      "[4.506384e+08]\n",
      "[4.5063894e+08]\n",
      "[4.506395e+08]\n",
      "[4.5064e+08]\n",
      "[4.5064064e+08]\n",
      "[4.506411e+08]\n",
      "[4.506416e+08]\n",
      "[4.5064224e+08]\n",
      "[4.5064275e+08]\n",
      "[4.5064326e+08]\n",
      "[4.506439e+08]\n",
      "[4.506505e+08]\n",
      "[4.506444e+08]\n",
      "[4.50645e+08]\n",
      "[4.506455e+08]\n",
      "[4.5064608e+08]\n",
      "[4.5064662e+08]\n",
      "[4.506472e+08]\n",
      "[4.5064774e+08]\n",
      "[4.5064826e+08]\n",
      "[4.5064883e+08]\n",
      "[4.506494e+08]\n",
      "[4.5062912e+08]\n",
      "[4.506297e+08]\n",
      "[4.5063027e+08]\n",
      "[4.506308e+08]\n",
      "[4.506507e+08]\n",
      "[4.506314e+08]\n",
      "[4.506319e+08]\n",
      "[4.5063242e+08]\n",
      "[4.5063302e+08]\n",
      "[4.5063357e+08]\n",
      "[4.506341e+08]\n",
      "[4.506347e+08]\n",
      "[4.506352e+08]\n",
      "[4.506358e+08]\n",
      "[4.5063632e+08]\n",
      "[4.5063686e+08]\n",
      "[4.5063744e+08]\n",
      "[4.5063795e+08]\n",
      "[4.5063853e+08]\n",
      "[4.5063914e+08]\n",
      "[4.506396e+08]\n",
      "[4.506402e+08]\n",
      "[4.5064077e+08]\n",
      "[4.5064128e+08]\n",
      "[4.506418e+08]\n",
      "[4.506424e+08]\n",
      "[4.5064294e+08]\n",
      "[4.506435e+08]\n",
      "[4.506441e+08]\n",
      "[4.506446e+08]\n",
      "[4.5065126e+08]\n",
      "[4.506452e+08]\n",
      "[4.506457e+08]\n",
      "[4.5064627e+08]\n",
      "[4.506468e+08]\n",
      "[4.5064733e+08]\n",
      "[4.5064797e+08]\n",
      "[4.5064845e+08]\n",
      "[4.506491e+08]\n",
      "[4.5064957e+08]\n",
      "[4.506501e+08]\n",
      "[4.5062986e+08]\n",
      "[4.506304e+08]\n",
      "[4.5063098e+08]\n",
      "[4.5063158e+08]\n",
      "[4.506514e+08]\n",
      "[4.5063213e+08]\n",
      "[4.5063267e+08]\n",
      "[4.5063315e+08]\n",
      "[4.5063373e+08]\n",
      "[4.506343e+08]\n",
      "[4.5063488e+08]\n",
      "[4.5063542e+08]\n",
      "[4.5063597e+08]\n",
      "[4.5063648e+08]\n",
      "[4.506371e+08]\n",
      "[4.5063763e+08]\n",
      "[4.5063814e+08]\n",
      "[4.5063872e+08]\n",
      "[4.506393e+08]\n",
      "[4.506398e+08]\n",
      "[4.506404e+08]\n",
      "[4.5064093e+08]\n",
      "[4.5064144e+08]\n",
      "[4.5064208e+08]\n",
      "[4.5064262e+08]\n",
      "[4.5064307e+08]\n",
      "[4.5064365e+08]\n",
      "[4.506443e+08]\n",
      "[4.5064474e+08]\n",
      "[4.5064538e+08]\n",
      "[4.506519e+08]\n",
      "[4.5064595e+08]\n",
      "[4.5064643e+08]\n",
      "[4.5064698e+08]\n",
      "[4.5064746e+08]\n",
      "[4.5064806e+08]\n",
      "[4.5064864e+08]\n",
      "[4.506492e+08]\n",
      "[4.5064973e+08]\n",
      "[4.506503e+08]\n",
      "[4.5065088e+08]\n",
      "[4.506306e+08]\n",
      "[4.5063117e+08]\n",
      "[4.5063178e+08]\n",
      "[4.5063226e+08]\n",
      "[4.506521e+08]\n",
      "[4.5063286e+08]\n",
      "[4.5063344e+08]\n",
      "[4.5063392e+08]\n",
      "[4.5063446e+08]\n",
      "[4.5063507e+08]\n",
      "[4.506356e+08]\n",
      "[4.5063616e+08]\n",
      "[4.5063667e+08]\n",
      "[4.506373e+08]\n",
      "[4.506378e+08]\n",
      "[4.5063837e+08]\n",
      "[4.5063888e+08]\n",
      "[4.5063946e+08]\n",
      "[4.5063994e+08]\n",
      "[4.5064064e+08]\n",
      "[4.506411e+08]\n",
      "[4.506416e+08]\n",
      "[4.5064224e+08]\n",
      "[4.5064278e+08]\n",
      "[4.5064333e+08]\n",
      "[4.506439e+08]\n",
      "[4.506444e+08]\n",
      "[4.5064493e+08]\n",
      "[4.506455e+08]\n",
      "[4.5064608e+08]\n",
      "[4.5065267e+08]\n",
      "[4.5064666e+08]\n",
      "[4.5064717e+08]\n",
      "[4.5064774e+08]\n",
      "[4.5064826e+08]\n",
      "[4.5064883e+08]\n",
      "[4.506494e+08]\n",
      "[4.5064992e+08]\n",
      "[4.506505e+08]\n",
      "[4.5065107e+08]\n",
      "[4.5065155e+08]\n",
      "[4.5063136e+08]\n",
      "[4.5063187e+08]\n",
      "[4.5063245e+08]\n",
      "[4.50633e+08]\n",
      "[4.506528e+08]\n",
      "[4.5063354e+08]\n",
      "[4.506341e+08]\n",
      "[4.5063466e+08]\n",
      "[4.506352e+08]\n",
      "[4.506358e+08]\n",
      "[4.506363e+08]\n",
      "[4.5063686e+08]\n",
      "[4.5063744e+08]\n",
      "[4.5063795e+08]\n",
      "[4.506385e+08]\n",
      "[4.5063904e+08]\n",
      "[4.506396e+08]\n",
      "[4.5064016e+08]\n",
      "[4.5064077e+08]\n",
      "[4.5064128e+08]\n",
      "[4.506418e+08]\n",
      "[4.5064237e+08]\n",
      "[4.5064294e+08]\n",
      "[4.506435e+08]\n",
      "[4.506441e+08]\n",
      "[4.5064454e+08]\n",
      "[4.506452e+08]\n",
      "[4.506457e+08]\n",
      "[4.506462e+08]\n",
      "[4.506468e+08]\n",
      "[4.506534e+08]\n",
      "[4.506473e+08]\n",
      "[4.5064794e+08]\n",
      "[4.5064842e+08]\n",
      "[4.5064906e+08]\n",
      "[4.5064954e+08]\n",
      "[4.506501e+08]\n",
      "[4.506507e+08]\n",
      "[4.5065123e+08]\n",
      "[4.5065178e+08]\n",
      "[4.5065235e+08]\n",
      "[4.5063213e+08]\n",
      "[4.5063264e+08]\n",
      "[4.5063318e+08]\n",
      "[4.5063373e+08]\n",
      "[4.5065363e+08]\n",
      "[4.5063427e+08]\n",
      "[4.5063485e+08]\n",
      "[4.5063542e+08]\n",
      "[4.5063597e+08]\n",
      "[4.5063648e+08]\n",
      "[4.506371e+08]\n",
      "[4.5063763e+08]\n",
      "[4.5063808e+08]\n",
      "[4.5063866e+08]\n",
      "[4.506393e+08]\n",
      "[4.506398e+08]\n",
      "[4.506404e+08]\n",
      "[4.5064093e+08]\n",
      "[4.506414e+08]\n",
      "[4.5064205e+08]\n",
      "[4.5064256e+08]\n",
      "[4.506431e+08]\n",
      "[4.5064365e+08]\n",
      "[4.5064422e+08]\n",
      "[4.5064474e+08]\n",
      "[4.5064538e+08]\n",
      "[4.506459e+08]\n",
      "[4.506464e+08]\n",
      "[4.5064698e+08]\n",
      "[4.506475e+08]\n",
      "[4.506542e+08]\n",
      "[4.5064806e+08]\n",
      "[4.506486e+08]\n",
      "[4.5064928e+08]\n",
      "[4.5064973e+08]\n",
      "[4.5065027e+08]\n",
      "[4.5065088e+08]\n",
      "[4.506514e+08]\n",
      "[4.506519e+08]\n",
      "[4.506525e+08]\n",
      "[4.50653e+08]\n",
      "[4.5063286e+08]\n",
      "[4.506334e+08]\n",
      "[4.5063392e+08]\n",
      "[4.5063443e+08]\n",
      "[4.5065434e+08]\n",
      "[4.50635e+08]\n",
      "[4.506356e+08]\n",
      "[4.5063613e+08]\n",
      "[4.5063664e+08]\n",
      "[4.506373e+08]\n",
      "[4.5063776e+08]\n",
      "[4.5063834e+08]\n",
      "[4.5063888e+08]\n",
      "[4.5063942e+08]\n",
      "[4.5063994e+08]\n",
      "[4.5064064e+08]\n",
      "[4.506411e+08]\n",
      "[4.506416e+08]\n",
      "[4.5064224e+08]\n",
      "[4.5064275e+08]\n",
      "[4.5064326e+08]\n",
      "[4.506439e+08]\n",
      "[4.5064438e+08]\n",
      "[4.5064493e+08]\n",
      "[4.506455e+08]\n",
      "[4.5064608e+08]\n",
      "[4.5064662e+08]\n",
      "[4.5064717e+08]\n",
      "[4.506477e+08]\n",
      "[4.5064826e+08]\n",
      "[4.506549e+08]\n",
      "[4.5064883e+08]\n",
      "[4.506494e+08]\n",
      "[4.5064992e+08]\n",
      "[4.5065046e+08]\n",
      "[4.50651e+08]\n",
      "[4.506516e+08]\n",
      "[4.506521e+08]\n",
      "[4.5065264e+08]\n",
      "[4.5065322e+08]\n",
      "[4.5065382e+08]\n",
      "[4.5063354e+08]\n",
      "[4.506341e+08]\n",
      "[4.5063462e+08]\n",
      "[4.5063514e+08]\n",
      "[4.5065507e+08]\n",
      "[4.5063578e+08]\n",
      "[4.506363e+08]\n",
      "[4.5063686e+08]\n",
      "[4.5063744e+08]\n",
      "[4.5063795e+08]\n",
      "[4.506385e+08]\n",
      "[4.506391e+08]\n",
      "[4.506396e+08]\n",
      "[4.5064016e+08]\n",
      "[4.5064074e+08]\n",
      "[4.5064128e+08]\n",
      "[4.506418e+08]\n",
      "[4.506424e+08]\n",
      "[4.5064288e+08]\n",
      "[4.5064346e+08]\n",
      "[4.506441e+08]\n",
      "[4.506446e+08]\n",
      "[4.506452e+08]\n",
      "[4.506457e+08]\n",
      "[4.506462e+08]\n",
      "[4.506468e+08]\n",
      "[4.506473e+08]\n",
      "[4.5064794e+08]\n",
      "[4.5064845e+08]\n",
      "[4.5064902e+08]\n",
      "[4.506556e+08]\n",
      "[4.506496e+08]\n",
      "[4.506501e+08]\n",
      "[4.506507e+08]\n",
      "[4.5065123e+08]\n",
      "[4.5065178e+08]\n",
      "[4.5065235e+08]\n",
      "[4.506528e+08]\n",
      "[4.5065344e+08]\n",
      "[4.50654e+08]\n",
      "[4.5065453e+08]\n",
      "[4.5063424e+08]\n",
      "[4.5063485e+08]\n",
      "[4.5063542e+08]\n",
      "[4.5063597e+08]\n",
      "[4.5065574e+08]\n",
      "[4.5063648e+08]\n",
      "[4.5063706e+08]\n",
      "[4.5063763e+08]\n",
      "[4.5063808e+08]\n",
      "[4.5063872e+08]\n",
      "[4.506393e+08]\n",
      "[4.506398e+08]\n",
      "[4.506404e+08]\n",
      "[4.506409e+08]\n",
      "[4.506414e+08]\n",
      "[4.50642e+08]\n",
      "[4.506426e+08]\n",
      "[4.5064307e+08]\n",
      "[4.5064365e+08]\n",
      "[4.5064422e+08]\n",
      "[4.5064474e+08]\n",
      "[4.5064538e+08]\n",
      "[4.506459e+08]\n",
      "[4.506464e+08]\n",
      "[4.5064698e+08]\n",
      "[4.5064746e+08]\n",
      "[4.5064806e+08]\n",
      "[4.5064864e+08]\n",
      "[4.5064925e+08]\n",
      "[4.5064973e+08]\n",
      "[4.506564e+08]\n",
      "[4.506503e+08]\n",
      "[4.5065088e+08]\n",
      "[4.506514e+08]\n",
      "[4.506519e+08]\n",
      "[4.5065248e+08]\n",
      "[4.50653e+08]\n",
      "[4.506536e+08]\n",
      "[4.506542e+08]\n",
      "[4.5065472e+08]\n",
      "[4.5065526e+08]\n",
      "[4.5063498e+08]\n",
      "[4.506356e+08]\n",
      "[4.5063613e+08]\n",
      "[4.5063667e+08]\n",
      "[4.5065654e+08]\n",
      "[4.5063725e+08]\n",
      "[4.5063776e+08]\n",
      "[4.5063834e+08]\n",
      "[4.5063885e+08]\n",
      "[4.5063942e+08]\n",
      "[4.5063994e+08]\n",
      "[4.5064058e+08]\n",
      "[4.506411e+08]\n",
      "[4.506416e+08]\n",
      "[4.5064224e+08]\n",
      "[4.5064272e+08]\n",
      "[4.5064326e+08]\n",
      "[4.5064384e+08]\n",
      "[4.5064435e+08]\n",
      "[4.5064493e+08]\n",
      "[4.506455e+08]\n",
      "[4.5064605e+08]\n",
      "[4.506466e+08]\n",
      "[4.5064717e+08]\n",
      "[4.5064765e+08]\n",
      "[4.5064826e+08]\n",
      "[4.5064883e+08]\n",
      "[4.506494e+08]\n",
      "[4.5064992e+08]\n",
      "[4.5065046e+08]\n",
      "[4.5065702e+08]\n",
      "[4.50651e+08]\n",
      "[4.5065155e+08]\n",
      "[4.506521e+08]\n",
      "[4.5065264e+08]\n",
      "[4.5065322e+08]\n",
      "[4.5065382e+08]\n",
      "[4.506543e+08]\n",
      "[4.506549e+08]\n",
      "[4.506555e+08]\n",
      "[4.50656e+08]\n",
      "[4.5063578e+08]\n",
      "[4.506363e+08]\n",
      "[4.506368e+08]\n",
      "[4.506374e+08]\n",
      "[4.5065725e+08]\n",
      "[4.506379e+08]\n",
      "[4.506385e+08]\n",
      "[4.5063907e+08]\n",
      "[4.506396e+08]\n",
      "[4.5064016e+08]\n",
      "[4.5064074e+08]\n",
      "[4.5064128e+08]\n",
      "[4.5064173e+08]\n",
      "[4.5064237e+08]\n",
      "[4.5064294e+08]\n",
      "[4.506435e+08]\n",
      "[4.506441e+08]\n",
      "[4.5064454e+08]\n",
      "[4.5064515e+08]\n",
      "[4.506457e+08]\n",
      "[4.506462e+08]\n",
      "[4.506468e+08]\n",
      "[4.5064726e+08]\n",
      "[4.5064794e+08]\n",
      "[4.5064842e+08]\n",
      "[4.5064902e+08]\n",
      "[4.5064954e+08]\n",
      "[4.506501e+08]\n",
      "[4.506507e+08]\n",
      "[4.5065126e+08]\n",
      "[4.506578e+08]\n",
      "[4.5065178e+08]\n",
      "[4.5065235e+08]\n",
      "[4.506528e+08]\n",
      "[4.5065344e+08]\n",
      "[4.50654e+08]\n",
      "[4.5065453e+08]\n",
      "[4.5065507e+08]\n",
      "[4.506556e+08]\n",
      "[4.506562e+08]\n",
      "[4.5065677e+08]\n",
      "[4.5063648e+08]\n",
      "[4.5063706e+08]\n",
      "[4.5063763e+08]\n",
      "[4.5063808e+08]\n",
      "[4.5065805e+08]\n",
      "[4.506387e+08]\n",
      "[4.5063926e+08]\n",
      "[4.5063978e+08]\n",
      "[4.506404e+08]\n",
      "[4.5064093e+08]\n",
      "[4.506414e+08]\n",
      "[4.50642e+08]\n",
      "[4.5064256e+08]\n",
      "[4.5064307e+08]\n",
      "[4.5064365e+08]\n",
      "[4.5064422e+08]\n",
      "[4.5064474e+08]\n",
      "[4.5064538e+08]\n",
      "[4.506459e+08]\n",
      "[4.506464e+08]\n",
      "[4.5064698e+08]\n",
      "[4.5064746e+08]\n",
      "[4.5064806e+08]\n",
      "[4.5064864e+08]\n",
      "[4.506492e+08]\n",
      "[4.5064973e+08]\n",
      "[4.5065024e+08]\n",
      "[4.5065088e+08]\n",
      "[4.5065136e+08]\n",
      "[4.506519e+08]\n",
      "[4.5065856e+08]\n",
      "[4.5065248e+08]\n",
      "[4.50653e+08]\n",
      "[4.5065357e+08]\n",
      "[4.506542e+08]\n",
      "[4.5065472e+08]\n",
      "[4.5065523e+08]\n",
      "[4.5065574e+08]\n",
      "[4.506564e+08]\n",
      "[4.5065686e+08]\n",
      "[4.5065744e+08]\n",
      "[4.5063725e+08]\n",
      "[4.5063776e+08]\n",
      "[4.5063834e+08]\n",
      "[4.5063888e+08]\n",
      "[4.5065875e+08]\n",
      "[4.5063942e+08]\n",
      "[4.5063994e+08]\n",
      "[4.5064064e+08]\n",
      "[4.506411e+08]\n",
      "[4.506416e+08]\n",
      "[4.506422e+08]\n",
      "[4.506427e+08]\n",
      "[4.5064323e+08]\n",
      "[4.5064384e+08]\n",
      "[4.5064435e+08]\n",
      "[4.5064493e+08]\n",
      "[4.506455e+08]\n",
      "[4.5064605e+08]\n",
      "[4.506466e+08]\n",
      "[4.5064717e+08]\n",
      "[4.5064765e+08]\n",
      "[4.5064826e+08]\n",
      "[4.5064883e+08]\n",
      "[4.506494e+08]\n",
      "[4.5064992e+08]\n",
      "[4.5065046e+08]\n",
      "[4.50651e+08]\n",
      "[4.5065152e+08]\n",
      "[4.506521e+08]\n",
      "[4.506526e+08]\n",
      "[4.5065933e+08]\n",
      "[4.5065322e+08]\n",
      "[4.5065382e+08]\n",
      "[4.5065434e+08]\n",
      "[4.506549e+08]\n",
      "[4.506555e+08]\n",
      "[4.5065594e+08]\n",
      "[4.506565e+08]\n",
      "[4.5065702e+08]\n",
      "[4.506576e+08]\n",
      "[4.5065818e+08]\n",
      "[4.506379e+08]\n",
      "[4.506385e+08]\n",
      "[4.5063904e+08]\n",
      "[4.506396e+08]\n",
      "[4.506595e+08]\n",
      "[4.5064013e+08]\n",
      "[4.506407e+08]\n",
      "[4.5064128e+08]\n",
      "[4.506417e+08]\n",
      "[4.5064237e+08]\n",
      "[4.506429e+08]\n",
      "[4.5064346e+08]\n",
      "[4.506441e+08]\n",
      "[4.5064454e+08]\n",
      "[4.5064515e+08]\n",
      "[4.506457e+08]\n",
      "[4.506462e+08]\n",
      "[4.506468e+08]\n",
      "[4.506473e+08]\n",
      "[4.5064794e+08]\n",
      "[4.506484e+08]\n",
      "[4.5064902e+08]\n",
      "[4.5064957e+08]\n",
      "[4.5065005e+08]\n",
      "[4.506507e+08]\n",
      "[4.506512e+08]\n",
      "[4.506517e+08]\n",
      "[4.5065235e+08]\n",
      "[4.506528e+08]\n",
      "[4.5065338e+08]\n",
      "[4.5066003e+08]\n",
      "[4.50654e+08]\n",
      "[4.5065453e+08]\n",
      "[4.5065504e+08]\n",
      "[4.506556e+08]\n",
      "[4.506562e+08]\n",
      "[4.5065677e+08]\n",
      "[4.506572e+08]\n",
      "[4.506578e+08]\n",
      "[4.506583e+08]\n",
      "[4.5065894e+08]\n",
      "[4.5063866e+08]\n",
      "[4.5063926e+08]\n",
      "[4.5063978e+08]\n",
      "[4.506404e+08]\n",
      "[4.506602e+08]\n",
      "[4.506409e+08]\n",
      "[4.506414e+08]\n",
      "[4.50642e+08]\n",
      "[4.5064256e+08]\n",
      "[4.5064307e+08]\n",
      "[4.5064365e+08]\n",
      "[4.5064422e+08]\n",
      "[4.5064474e+08]\n",
      "[4.5064538e+08]\n",
      "[4.506459e+08]\n",
      "[4.506464e+08]\n",
      "[4.5064698e+08]\n",
      "[4.5064746e+08]\n",
      "[4.5064806e+08]\n",
      "[4.5064858e+08]\n",
      "[4.506492e+08]\n",
      "[4.5064973e+08]\n",
      "[4.5065024e+08]\n",
      "[4.5065085e+08]\n",
      "[4.5065133e+08]\n",
      "[4.506519e+08]\n",
      "[4.5065248e+08]\n",
      "[4.50653e+08]\n",
      "[4.5065357e+08]\n",
      "[4.506542e+08]\n",
      "[4.5066077e+08]\n",
      "[4.5065472e+08]\n",
      "[4.5065523e+08]\n",
      "[4.5065574e+08]\n",
      "[4.506564e+08]\n",
      "[4.5065686e+08]\n",
      "[4.5065744e+08]\n",
      "[4.5065802e+08]\n",
      "[4.5065853e+08]\n",
      "[4.506591e+08]\n",
      "[4.506597e+08]\n",
      "[4.5063942e+08]\n",
      "[4.5063994e+08]\n",
      "[4.5064058e+08]\n",
      "[4.506411e+08]\n",
      "[4.5066093e+08]\n",
      "[4.5064154e+08]\n",
      "[4.506422e+08]\n",
      "[4.5064275e+08]\n",
      "[4.506432e+08]\n",
      "[4.5064384e+08]\n",
      "[4.5064435e+08]\n",
      "[4.5064493e+08]\n",
      "[4.506455e+08]\n",
      "[4.5064605e+08]\n",
      "[4.506466e+08]\n",
      "[4.5064717e+08]\n",
      "[4.506476e+08]\n",
      "[4.5064822e+08]\n",
      "[4.5064877e+08]\n",
      "[4.506494e+08]\n",
      "[4.5064992e+08]\n",
      "[4.5065046e+08]\n",
      "[4.50651e+08]\n",
      "[4.5065155e+08]\n",
      "[4.5065206e+08]\n",
      "[4.506526e+08]\n",
      "[4.506532e+08]\n",
      "[4.5065382e+08]\n",
      "[4.5065434e+08]\n",
      "[4.506549e+08]\n",
      "[4.5066144e+08]\n",
      "[4.5065542e+08]\n",
      "[4.5065594e+08]\n",
      "[4.506565e+08]\n",
      "[4.50657e+08]\n",
      "[4.506576e+08]\n",
      "[4.5065818e+08]\n",
      "[4.5065875e+08]\n",
      "[4.506593e+08]\n",
      "[4.5065987e+08]\n",
      "[4.5066035e+08]\n",
      "[4.5064016e+08]\n",
      "[4.5064067e+08]\n",
      "[4.5064128e+08]\n",
      "[4.5064173e+08]\n",
      "[4.506617e+08]\n",
      "[4.5064237e+08]\n",
      "[4.5064288e+08]\n",
      "[4.5064346e+08]\n",
      "[4.506441e+08]\n",
      "[4.5064454e+08]\n",
      "[4.5064512e+08]\n",
      "[4.506457e+08]\n",
      "[4.506462e+08]\n",
      "[4.506468e+08]\n",
      "[4.506473e+08]\n",
      "[4.5064794e+08]\n",
      "[4.5064842e+08]\n",
      "[4.5064896e+08]\n",
      "[4.5064954e+08]\n",
      "[4.5065005e+08]\n",
      "[4.5065062e+08]\n",
      "[4.506512e+08]\n",
      "[4.506517e+08]\n",
      "[4.5065232e+08]\n",
      "[4.506528e+08]\n",
      "[4.5065338e+08]\n",
      "[4.5065398e+08]\n",
      "[4.5065453e+08]\n",
      "[4.5065504e+08]\n",
      "[4.506556e+08]\n",
      "[4.506622e+08]\n",
      "[4.5065616e+08]\n",
      "[4.5065674e+08]\n",
      "[4.5065725e+08]\n",
      "[4.5065776e+08]\n",
      "[4.5065834e+08]\n",
      "[4.5065888e+08]\n",
      "[4.5065946e+08]\n",
      "[4.5066003e+08]\n",
      "[4.5066054e+08]\n",
      "[4.5066106e+08]\n",
      "[4.506351e+08]\n",
      "[4.5063565e+08]\n",
      "[4.506362e+08]\n",
      "[4.5063674e+08]\n",
      "[4.5065667e+08]\n",
      "[4.5063738e+08]\n",
      "[4.5063782e+08]\n",
      "[4.5063846e+08]\n",
      "[4.5063898e+08]\n",
      "[4.5063955e+08]\n",
      "[4.5064006e+08]\n",
      "[4.5064064e+08]\n",
      "[4.506412e+08]\n",
      "[4.5064166e+08]\n",
      "[4.506423e+08]\n",
      "[4.506428e+08]\n",
      "[4.506434e+08]\n",
      "[4.5064403e+08]\n",
      "[4.5064445e+08]\n",
      "[4.5064506e+08]\n",
      "[4.506456e+08]\n",
      "[4.5064618e+08]\n",
      "[4.5064672e+08]\n",
      "[4.5064723e+08]\n",
      "[4.5064787e+08]\n",
      "[4.5064832e+08]\n",
      "[4.506489e+08]\n",
      "[4.5064947e+08]\n",
      "[4.5065005e+08]\n",
      "[4.5065056e+08]\n",
      "[4.5065715e+08]\n",
      "[4.5065107e+08]\n",
      "[4.5065165e+08]\n",
      "[4.5065222e+08]\n",
      "[4.5065274e+08]\n",
      "[4.506533e+08]\n",
      "[4.506539e+08]\n",
      "[4.5065446e+08]\n",
      "[4.50655e+08]\n",
      "[4.5065555e+08]\n",
      "[4.5065606e+08]\n",
      "[4.5063584e+08]\n",
      "[4.506364e+08]\n",
      "[4.5063693e+08]\n",
      "[4.506375e+08]\n",
      "[4.5065738e+08]\n",
      "[4.50638e+08]\n",
      "[4.506386e+08]\n",
      "[4.5063917e+08]\n",
      "[4.5063968e+08]\n",
      "[4.5064026e+08]\n",
      "[4.5064083e+08]\n",
      "[4.5064134e+08]\n",
      "[4.5064186e+08]\n",
      "[4.506425e+08]\n",
      "[4.50643e+08]\n",
      "[4.506436e+08]\n",
      "[4.5064416e+08]\n",
      "[4.5064467e+08]\n",
      "[4.5064525e+08]\n",
      "[4.5064582e+08]\n",
      "[4.506463e+08]\n",
      "[4.5064688e+08]\n",
      "[4.5064736e+08]\n",
      "[4.50648e+08]\n",
      "[4.506485e+08]\n",
      "[4.5064915e+08]\n",
      "[4.506497e+08]\n",
      "[4.5065018e+08]\n",
      "[4.506508e+08]\n",
      "[4.5065133e+08]\n",
      "[4.5065792e+08]\n",
      "[4.5065184e+08]\n",
      "[4.506524e+08]\n",
      "[4.5065293e+08]\n",
      "[4.506535e+08]\n",
      "[4.5065408e+08]\n",
      "[4.5065462e+08]\n",
      "[4.5065517e+08]\n",
      "[4.5065568e+08]\n",
      "[4.5065632e+08]\n",
      "[4.5065683e+08]\n",
      "[4.5063654e+08]\n",
      "[4.5063715e+08]\n",
      "[4.506377e+08]\n",
      "[4.506382e+08]\n",
      "[4.506581e+08]\n",
      "[4.506388e+08]\n",
      "[4.5063936e+08]\n",
      "[4.5063984e+08]\n",
      "[4.5064048e+08]\n",
      "[4.50641e+08]\n",
      "[4.5064147e+08]\n",
      "[4.5064214e+08]\n",
      "[4.506427e+08]\n",
      "[4.5064314e+08]\n",
      "[4.506437e+08]\n",
      "[4.506443e+08]\n",
      "[4.5064486e+08]\n",
      "[4.5064544e+08]\n",
      "[4.50646e+08]\n",
      "[4.5064653e+08]\n",
      "[4.506471e+08]\n",
      "[4.5064755e+08]\n",
      "[4.5064813e+08]\n",
      "[4.506487e+08]\n",
      "[4.506493e+08]\n",
      "[4.5064982e+08]\n",
      "[4.5065037e+08]\n",
      "[4.5065094e+08]\n",
      "[4.5065142e+08]\n",
      "[4.50652e+08]\n",
      "[4.5065866e+08]\n",
      "[4.5065254e+08]\n",
      "[4.5065312e+08]\n",
      "[4.506537e+08]\n",
      "[4.5065424e+08]\n",
      "[4.5065485e+08]\n",
      "[4.5065536e+08]\n",
      "[4.5065584e+08]\n",
      "[4.5065645e+08]\n",
      "[4.5065696e+08]\n",
      "[4.5065754e+08]\n",
      "[4.5063738e+08]\n",
      "[4.5063782e+08]\n",
      "[4.506384e+08]\n",
      "[4.5063898e+08]\n",
      "[4.5065888e+08]\n",
      "[4.5063955e+08]\n",
      "[4.5064003e+08]\n",
      "[4.5064064e+08]\n",
      "[4.506412e+08]\n",
      "[4.5064163e+08]\n",
      "[4.5064227e+08]\n",
      "[4.506428e+08]\n",
      "[4.506434e+08]\n",
      "[4.5064397e+08]\n",
      "[4.5064448e+08]\n",
      "[4.5064506e+08]\n",
      "[4.506456e+08]\n",
      "[4.5064614e+08]\n",
      "[4.5064672e+08]\n",
      "[4.5064723e+08]\n",
      "[4.506478e+08]\n",
      "[4.5064832e+08]\n",
      "[4.506489e+08]\n",
      "[4.5064947e+08]\n",
      "[4.5065005e+08]\n",
      "[4.5065056e+08]\n",
      "[4.5065107e+08]\n",
      "[4.5065165e+08]\n",
      "[4.506522e+08]\n",
      "[4.5065274e+08]\n",
      "[4.5065946e+08]\n",
      "[4.506533e+08]\n",
      "[4.506539e+08]\n",
      "[4.5065443e+08]\n",
      "[4.50655e+08]\n",
      "[4.5065555e+08]\n",
      "[4.5065606e+08]\n",
      "[4.506567e+08]\n",
      "[4.5065715e+08]\n",
      "[4.506577e+08]\n",
      "[4.506583e+08]\n",
      "[4.5063798e+08]\n",
      "[4.506386e+08]\n",
      "[4.5063917e+08]\n",
      "[4.5063968e+08]\n",
      "[4.5065962e+08]\n",
      "[4.5064026e+08]\n",
      "[4.5064083e+08]\n",
      "[4.5064138e+08]\n",
      "[4.506419e+08]\n",
      "[4.5064246e+08]\n",
      "[4.50643e+08]\n",
      "[4.506436e+08]\n",
      "[4.5064416e+08]\n",
      "[4.5064464e+08]\n",
      "[4.506453e+08]\n",
      "[4.5064582e+08]\n",
      "[4.5064627e+08]\n",
      "[4.5064682e+08]\n",
      "[4.5064736e+08]\n",
      "[4.50648e+08]\n",
      "[4.506485e+08]\n",
      "[4.506491e+08]\n",
      "[4.5064963e+08]\n",
      "[4.5065018e+08]\n",
      "[4.5065078e+08]\n",
      "[4.506513e+08]\n",
      "[4.506518e+08]\n",
      "[4.506524e+08]\n",
      "[4.5065293e+08]\n",
      "[4.506535e+08]\n",
      "[4.506601e+08]\n",
      "[4.5065408e+08]\n",
      "[4.506546e+08]\n",
      "[4.5065517e+08]\n",
      "[4.5065568e+08]\n",
      "[4.5065626e+08]\n",
      "[4.5065683e+08]\n",
      "[4.5065734e+08]\n",
      "[4.506579e+08]\n",
      "[4.5065843e+08]\n",
      "[4.50659e+08]\n",
      "[4.506388e+08]\n",
      "[4.5063936e+08]\n",
      "[4.5063987e+08]\n",
      "[4.5064045e+08]\n",
      "[4.5066026e+08]\n",
      "[4.50641e+08]\n",
      "[4.506415e+08]\n",
      "[4.5064214e+08]\n",
      "[4.5064262e+08]\n",
      "[4.5064314e+08]\n",
      "[4.506437e+08]\n",
      "[4.506443e+08]\n",
      "[4.5064486e+08]\n",
      "[4.5064544e+08]\n",
      "[4.50646e+08]\n",
      "[4.506465e+08]\n",
      "[4.5064704e+08]\n",
      "[4.5064755e+08]\n",
      "[4.5064813e+08]\n",
      "[4.506487e+08]\n",
      "[4.5064928e+08]\n",
      "[4.5064982e+08]\n",
      "[4.5065037e+08]\n",
      "[4.5065094e+08]\n",
      "[4.506514e+08]\n",
      "[4.50652e+08]\n",
      "[4.5065254e+08]\n",
      "[4.5065312e+08]\n",
      "[4.5065373e+08]\n",
      "[4.5065424e+08]\n",
      "[4.5066086e+08]\n",
      "[4.5065485e+08]\n",
      "[4.5065536e+08]\n",
      "[4.5065584e+08]\n",
      "[4.5065645e+08]\n",
      "[4.5065696e+08]\n",
      "[4.5065754e+08]\n",
      "[4.506581e+08]\n",
      "[4.5065866e+08]\n",
      "[4.506592e+08]\n",
      "[4.506598e+08]\n",
      "[4.5063955e+08]\n",
      "[4.5064e+08]\n",
      "[4.5064064e+08]\n",
      "[4.506412e+08]\n",
      "[4.50661e+08]\n",
      "[4.506416e+08]\n",
      "[4.5064224e+08]\n",
      "[4.506428e+08]\n",
      "[4.5064336e+08]\n",
      "[4.5064397e+08]\n",
      "[4.5064445e+08]\n",
      "[4.5064506e+08]\n",
      "[4.506456e+08]\n",
      "[4.5064614e+08]\n",
      "[4.5064672e+08]\n",
      "[4.5064723e+08]\n",
      "[4.506478e+08]\n",
      "[4.5064832e+08]\n",
      "[4.506489e+08]\n",
      "[4.5064947e+08]\n",
      "[4.5065e+08]\n",
      "[4.5065056e+08]\n",
      "[4.5065107e+08]\n",
      "[4.5065165e+08]\n",
      "[4.506522e+08]\n",
      "[4.506527e+08]\n",
      "[4.506533e+08]\n",
      "[4.506539e+08]\n",
      "[4.506544e+08]\n",
      "[4.5065498e+08]\n",
      "[4.5066157e+08]\n",
      "[4.5065555e+08]\n",
      "[4.5065606e+08]\n",
      "[4.5065664e+08]\n",
      "[4.5065712e+08]\n",
      "[4.5065766e+08]\n",
      "[4.506583e+08]\n",
      "[4.5065885e+08]\n",
      "[4.506594e+08]\n",
      "[4.5065997e+08]\n",
      "[4.5066045e+08]\n",
      "[4.5064022e+08]\n",
      "[4.5064083e+08]\n",
      "[4.5064138e+08]\n",
      "[4.5064186e+08]\n",
      "[4.5066176e+08]\n",
      "[4.5064246e+08]\n",
      "[4.50643e+08]\n",
      "[4.5064355e+08]\n",
      "[4.5064416e+08]\n",
      "[4.5064467e+08]\n",
      "[4.5064525e+08]\n",
      "[4.5064576e+08]\n",
      "[4.506463e+08]\n",
      "[4.5064682e+08]\n",
      "[4.5064736e+08]\n",
      "[4.50648e+08]\n",
      "[4.506485e+08]\n",
      "[4.506491e+08]\n",
      "[4.5064963e+08]\n",
      "[4.5065018e+08]\n",
      "[4.5065075e+08]\n",
      "[4.5065133e+08]\n",
      "[4.5065184e+08]\n",
      "[4.506524e+08]\n",
      "[4.506529e+08]\n",
      "[4.506535e+08]\n",
      "[4.5065408e+08]\n",
      "[4.506546e+08]\n",
      "[4.5065517e+08]\n",
      "[4.5065568e+08]\n",
      "[4.506623e+08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.5065626e+08]\n",
      "[4.5065683e+08]\n",
      "[4.506573e+08]\n",
      "[4.5065786e+08]\n",
      "[4.5065843e+08]\n",
      "[4.50659e+08]\n",
      "[4.5065962e+08]\n",
      "[4.506601e+08]\n",
      "[4.5066067e+08]\n",
      "[4.5066122e+08]\n",
      "[4.50641e+08]\n",
      "[4.5064147e+08]\n",
      "[4.506421e+08]\n",
      "[4.5064262e+08]\n",
      "[4.5066246e+08]\n",
      "[4.5064314e+08]\n",
      "[4.506437e+08]\n",
      "[4.506443e+08]\n",
      "[4.5064486e+08]\n",
      "[4.506454e+08]\n",
      "[4.5064598e+08]\n",
      "[4.506465e+08]\n",
      "[4.5064704e+08]\n",
      "[4.5064755e+08]\n",
      "[4.5064813e+08]\n",
      "[4.506487e+08]\n",
      "[4.5064928e+08]\n",
      "[4.506498e+08]\n",
      "[4.5065037e+08]\n",
      "[4.5065094e+08]\n",
      "[4.506514e+08]\n",
      "[4.5065197e+08]\n",
      "[4.5065254e+08]\n",
      "[4.5065312e+08]\n",
      "[4.506537e+08]\n",
      "[4.5065424e+08]\n",
      "[4.5065485e+08]\n",
      "[4.506553e+08]\n",
      "[4.506558e+08]\n",
      "[4.5065645e+08]\n",
      "[4.5066307e+08]\n",
      "[4.5065693e+08]\n",
      "[4.506575e+08]\n",
      "[4.506581e+08]\n",
      "[4.5065862e+08]\n",
      "[4.506592e+08]\n",
      "[4.506598e+08]\n",
      "[4.5066022e+08]\n",
      "[4.5066086e+08]\n",
      "[4.506614e+08]\n",
      "[4.5066195e+08]\n",
      "[4.506416e+08]\n",
      "[4.5064224e+08]\n",
      "[4.506428e+08]\n",
      "[4.5064336e+08]\n",
      "[4.5066326e+08]\n",
      "[4.5064394e+08]\n",
      "[4.5064448e+08]\n",
      "[4.5064506e+08]\n",
      "[4.5064557e+08]\n",
      "[4.5064614e+08]\n",
      "[4.5064672e+08]\n",
      "[4.506472e+08]\n",
      "[4.506478e+08]\n",
      "[4.506483e+08]\n",
      "[4.506489e+08]\n",
      "[4.5064947e+08]\n",
      "[4.5065e+08]\n",
      "[4.5065056e+08]\n",
      "[4.5065107e+08]\n",
      "[4.5065165e+08]\n",
      "[4.5065222e+08]\n",
      "[4.5065267e+08]\n",
      "[4.5065325e+08]\n",
      "[4.506539e+08]\n",
      "[4.506544e+08]\n",
      "[4.5065498e+08]\n",
      "[4.5065552e+08]\n",
      "[4.5065606e+08]\n",
      "[4.5065658e+08]\n",
      "[4.5065715e+08]\n",
      "[4.5066374e+08]\n",
      "[4.5065766e+08]\n",
      "[4.5065827e+08]\n",
      "[4.506588e+08]\n",
      "[4.506594e+08]\n",
      "[4.5065997e+08]\n",
      "[4.5066045e+08]\n",
      "[4.50661e+08]\n",
      "[4.5066157e+08]\n",
      "[4.5066214e+08]\n",
      "[4.506627e+08]\n",
      "[4.5064243e+08]\n",
      "[4.5064298e+08]\n",
      "[4.5064352e+08]\n",
      "[4.5064413e+08]\n",
      "[4.5066397e+08]\n",
      "[4.506446e+08]\n",
      "[4.506452e+08]\n",
      "[4.5064576e+08]\n",
      "[4.5064627e+08]\n",
      "[4.5064685e+08]\n",
      "[4.5064733e+08]\n",
      "[4.50648e+08]\n",
      "[4.506485e+08]\n",
      "[4.506491e+08]\n",
      "[4.5064966e+08]\n",
      "[4.5065018e+08]\n",
      "[4.5065075e+08]\n",
      "[4.5065126e+08]\n",
      "[4.506518e+08]\n",
      "[4.5065235e+08]\n",
      "[4.5065293e+08]\n",
      "[4.506535e+08]\n",
      "[4.5065408e+08]\n",
      "[4.5065462e+08]\n",
      "[4.5065517e+08]\n",
      "[4.5065568e+08]\n",
      "[4.5065626e+08]\n",
      "[4.5065683e+08]\n",
      "[4.5065734e+08]\n",
      "[4.5065786e+08]\n",
      "[4.506645e+08]\n",
      "[4.5065843e+08]\n",
      "[4.5065898e+08]\n",
      "[4.5065962e+08]\n",
      "[4.506601e+08]\n",
      "[4.5066067e+08]\n",
      "[4.5066122e+08]\n",
      "[4.5066176e+08]\n",
      "[4.506623e+08]\n",
      "[4.5066285e+08]\n",
      "[4.5066342e+08]\n",
      "[4.5064314e+08]\n",
      "[4.506437e+08]\n",
      "[4.506443e+08]\n",
      "[4.5064483e+08]\n",
      "[4.506647e+08]\n",
      "[4.5064544e+08]\n",
      "[4.5064598e+08]\n",
      "[4.5064646e+08]\n",
      "[4.5064704e+08]\n",
      "[4.5064755e+08]\n",
      "[4.5064813e+08]\n",
      "[4.506487e+08]\n",
      "[4.5064928e+08]\n",
      "[4.506498e+08]\n",
      "[4.5065037e+08]\n",
      "[4.506509e+08]\n",
      "[4.5065146e+08]\n",
      "[4.5065197e+08]\n",
      "[4.5065254e+08]\n",
      "[4.5065312e+08]\n",
      "[4.506537e+08]\n",
      "[4.5065424e+08]\n",
      "[4.5065485e+08]\n",
      "[4.506553e+08]\n",
      "[4.506558e+08]\n",
      "[4.5065642e+08]\n",
      "[4.5065693e+08]\n",
      "[4.5065747e+08]\n",
      "[4.506581e+08]\n",
      "[4.5065862e+08]\n",
      "[4.506652e+08]\n",
      "[4.506592e+08]\n",
      "[4.5065978e+08]\n",
      "[4.5066022e+08]\n",
      "[4.5066086e+08]\n",
      "[4.5066138e+08]\n",
      "[4.5066195e+08]\n",
      "[4.5066246e+08]\n",
      "[4.5066307e+08]\n",
      "[4.5066355e+08]\n",
      "[4.5066413e+08]\n",
      "[4.506439e+08]\n",
      "[4.506444e+08]\n",
      "[4.5064502e+08]\n",
      "[4.5064557e+08]\n",
      "[4.506654e+08]\n",
      "[4.506461e+08]\n",
      "[4.506467e+08]\n",
      "[4.506472e+08]\n",
      "[4.506478e+08]\n",
      "[4.506483e+08]\n",
      "[4.506489e+08]\n",
      "[4.5064944e+08]\n",
      "[4.5065e+08]\n",
      "[4.5065056e+08]\n",
      "[4.5065107e+08]\n",
      "[4.5065162e+08]\n",
      "[4.506522e+08]\n",
      "[4.5065267e+08]\n",
      "[4.5065325e+08]\n",
      "[4.506539e+08]\n",
      "[4.506544e+08]\n",
      "[4.5065498e+08]\n",
      "[4.5065555e+08]\n",
      "[4.50656e+08]\n",
      "[4.506566e+08]\n",
      "[4.506571e+08]\n",
      "[4.5065766e+08]\n",
      "[4.5065827e+08]\n",
      "[4.506588e+08]\n",
      "[4.5065933e+08]\n",
      "[4.50666e+08]\n",
      "[4.5065997e+08]\n",
      "[4.506604e+08]\n",
      "[4.5066096e+08]\n",
      "[4.506615e+08]\n",
      "[4.5066208e+08]\n",
      "[4.5066266e+08]\n",
      "[4.5066323e+08]\n",
      "[4.5066378e+08]\n",
      "[4.506644e+08]\n",
      "[4.5066496e+08]\n",
      "[4.506446e+08]\n",
      "[4.506452e+08]\n",
      "[4.5064576e+08]\n",
      "[4.5064627e+08]\n",
      "[4.5066618e+08]\n",
      "[4.5064682e+08]\n",
      "[4.5064733e+08]\n",
      "[4.50648e+08]\n",
      "[4.506485e+08]\n",
      "[4.506491e+08]\n",
      "[4.5064963e+08]\n",
      "[4.5065018e+08]\n",
      "[4.5065072e+08]\n",
      "[4.5065126e+08]\n",
      "[4.506518e+08]\n",
      "[4.5065235e+08]\n",
      "[4.506529e+08]\n",
      "[4.506535e+08]\n",
      "[4.50654e+08]\n",
      "[4.5065456e+08]\n",
      "[4.506551e+08]\n",
      "[4.5065568e+08]\n",
      "[4.5065626e+08]\n",
      "[4.5065683e+08]\n",
      "[4.5065728e+08]\n",
      "[4.506579e+08]\n",
      "[4.5065837e+08]\n",
      "[4.5065898e+08]\n",
      "[4.5065962e+08]\n",
      "[4.506601e+08]\n",
      "[4.5066675e+08]\n",
      "[4.5066067e+08]\n",
      "[4.5066115e+08]\n",
      "[4.5066176e+08]\n",
      "[4.5066227e+08]\n",
      "[4.5066285e+08]\n",
      "[4.5066342e+08]\n",
      "[4.50664e+08]\n",
      "[4.506645e+08]\n",
      "[4.506651e+08]\n",
      "[4.506656e+08]\n",
      "[4.5064538e+08]\n",
      "[4.5064598e+08]\n",
      "[4.5064653e+08]\n",
      "[4.5064704e+08]\n",
      "[4.5066688e+08]\n",
      "[4.5064755e+08]\n",
      "[4.506481e+08]\n",
      "[4.5064864e+08]\n",
      "[4.5064928e+08]\n",
      "[4.506498e+08]\n",
      "[4.5065037e+08]\n",
      "[4.506509e+08]\n",
      "[4.5065142e+08]\n",
      "[4.5065197e+08]\n",
      "[4.5065254e+08]\n",
      "[4.506531e+08]\n",
      "[4.506537e+08]\n",
      "[4.5065424e+08]\n",
      "[4.506548e+08]\n",
      "[4.506553e+08]\n",
      "[4.506558e+08]\n",
      "[4.5065642e+08]\n",
      "[4.506569e+08]\n",
      "[4.5065747e+08]\n",
      "[4.5065805e+08]\n",
      "[4.5065862e+08]\n",
      "[4.506592e+08]\n",
      "[4.5065978e+08]\n",
      "[4.5066026e+08]\n",
      "[4.5066086e+08]\n",
      "[4.5066746e+08]\n",
      "[4.5066138e+08]\n",
      "[4.5066195e+08]\n",
      "[4.5066246e+08]\n",
      "[4.506631e+08]\n",
      "[4.5066358e+08]\n",
      "[4.5066413e+08]\n",
      "[4.506647e+08]\n",
      "[4.506652e+08]\n",
      "[4.506658e+08]\n",
      "[4.5066634e+08]\n",
      "[4.506461e+08]\n",
      "[4.506467e+08]\n",
      "[4.5064717e+08]\n",
      "[4.5064778e+08]\n",
      "[4.5066765e+08]\n",
      "[4.506483e+08]\n",
      "[4.506489e+08]\n",
      "[4.5064947e+08]\n",
      "[4.5065e+08]\n",
      "[4.5065053e+08]\n",
      "[4.5065107e+08]\n",
      "[4.506516e+08]\n",
      "[4.506522e+08]\n",
      "[4.5065267e+08]\n",
      "[4.5065325e+08]\n",
      "[4.506539e+08]\n",
      "[4.5065437e+08]\n",
      "[4.5065494e+08]\n",
      "[4.5065552e+08]\n",
      "[4.50656e+08]\n",
      "[4.506566e+08]\n",
      "[4.506571e+08]\n",
      "[4.5065766e+08]\n",
      "[4.5065824e+08]\n",
      "[4.506588e+08]\n",
      "[4.5065933e+08]\n",
      "[4.5065997e+08]\n",
      "[4.506604e+08]\n",
      "[4.5066096e+08]\n",
      "[4.506615e+08]\n",
      "[4.506682e+08]\n",
      "[4.5066208e+08]\n",
      "[4.5066266e+08]\n",
      "[4.5066323e+08]\n",
      "[4.5066378e+08]\n",
      "[4.5066432e+08]\n",
      "[4.5066493e+08]\n",
      "[4.506654e+08]\n",
      "[4.5066595e+08]\n",
      "[4.506665e+08]\n",
      "[4.506671e+08]\n",
      "[4.5064682e+08]\n",
      "[4.5064733e+08]\n",
      "[4.5064794e+08]\n",
      "[4.506485e+08]\n",
      "[4.5066835e+08]\n",
      "[4.506491e+08]\n",
      "[4.506496e+08]\n",
      "[4.5065014e+08]\n",
      "[4.5065072e+08]\n",
      "[4.5065126e+08]\n",
      "[4.5065178e+08]\n",
      "[4.5065235e+08]\n",
      "[4.5065286e+08]\n",
      "[4.506535e+08]\n",
      "[4.50654e+08]\n",
      "[4.506546e+08]\n",
      "[4.506551e+08]\n",
      "[4.5065565e+08]\n",
      "[4.5065626e+08]\n",
      "[4.5065683e+08]\n",
      "[4.5065728e+08]\n",
      "[4.506579e+08]\n",
      "[4.5065837e+08]\n",
      "[4.5065898e+08]\n",
      "[4.506596e+08]\n",
      "[4.506601e+08]\n",
      "[4.5066064e+08]\n",
      "[4.506612e+08]\n",
      "[4.5066176e+08]\n",
      "[4.5066227e+08]\n",
      "[4.506689e+08]\n",
      "[4.5066285e+08]\n",
      "[4.5066342e+08]\n",
      "[4.50664e+08]\n",
      "[4.506645e+08]\n",
      "[4.5066506e+08]\n",
      "[4.5066563e+08]\n",
      "[4.506661e+08]\n",
      "[4.5066675e+08]\n",
      "[4.5066726e+08]\n",
      "[4.506678e+08]\n"
     ]
    }
   ],
   "source": [
    "for i in test_Y:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.drop(['id'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['AMT'] = test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REG_YYMM</th>\n",
       "      <th>CARD_SIDO_NM</th>\n",
       "      <th>STD_CLSS_NM</th>\n",
       "      <th>AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202004</td>\n",
       "      <td>강원</td>\n",
       "      <td>건강보조식품 소매업</td>\n",
       "      <td>450628416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202004</td>\n",
       "      <td>강원</td>\n",
       "      <td>골프장 운영업</td>\n",
       "      <td>450628928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202004</td>\n",
       "      <td>강원</td>\n",
       "      <td>과실 및 채소 소매업</td>\n",
       "      <td>450629568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202004</td>\n",
       "      <td>강원</td>\n",
       "      <td>관광 민예품 및 선물용품 소매업</td>\n",
       "      <td>450630080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202004</td>\n",
       "      <td>강원</td>\n",
       "      <td>그외 기타 분류안된 오락관련 서비스업</td>\n",
       "      <td>450649984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>202007</td>\n",
       "      <td>충북</td>\n",
       "      <td>피자 햄버거 샌드위치 및 유사 음식점업</td>\n",
       "      <td>450665632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>202007</td>\n",
       "      <td>충북</td>\n",
       "      <td>한식 음식점업</td>\n",
       "      <td>450666112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>202007</td>\n",
       "      <td>충북</td>\n",
       "      <td>호텔업</td>\n",
       "      <td>450666752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>202007</td>\n",
       "      <td>충북</td>\n",
       "      <td>화장품 및 방향제 소매업</td>\n",
       "      <td>450667264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>202007</td>\n",
       "      <td>충북</td>\n",
       "      <td>휴양콘도 운영업</td>\n",
       "      <td>450667808.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1394 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      REG_YYMM CARD_SIDO_NM            STD_CLSS_NM          AMT\n",
       "0       202004           강원             건강보조식품 소매업  450628416.0\n",
       "1       202004           강원                골프장 운영업  450628928.0\n",
       "2       202004           강원            과실 및 채소 소매업  450629568.0\n",
       "3       202004           강원      관광 민예품 및 선물용품 소매업  450630080.0\n",
       "4       202004           강원   그외 기타 분류안된 오락관련 서비스업  450649984.0\n",
       "...        ...          ...                    ...          ...\n",
       "1389    202007           충북  피자 햄버거 샌드위치 및 유사 음식점업  450665632.0\n",
       "1390    202007           충북                한식 음식점업  450666112.0\n",
       "1391    202007           충북                    호텔업  450666752.0\n",
       "1392    202007           충북          화장품 및 방향제 소매업  450667264.0\n",
       "1393    202007           충북               휴양콘도 운영업  450667808.0\n",
       "\n",
       "[1394 rows x 4 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.index.name = 'id'\n",
    "sub_df.to_csv('submission.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/submission.csv', index_col=0)\n",
    "submission = submission.drop(['AMT'], axis=1)\n",
    "submission = submission.merge(temp, left_on=['REG_YYMM', 'CARD_SIDO_NM', 'STD_CLSS_NM'], right_on=['REG_YYMM', 'CARD_SIDO_NM', 'STD_CLSS_NM'], how='left')\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('submission.csv', encoding='utf-8-sig')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
